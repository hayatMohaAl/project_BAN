{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d923a3d",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "465bbf60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T09:18:57.866654Z",
     "start_time": "2022-01-13T09:18:57.851682Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import string \n",
    "import re\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "# import nltk\n",
    "# from nltk.corpus import wordnet\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "# #from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
    "#from nltk.corpus import stopwords\n",
    "\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import spacy\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# from tensorflow.keras import Sequential, layers\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "# from tensorflow.keras import models\n",
    "\n",
    "from sklearn.utils import resample\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3fd507c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T09:18:58.784253Z",
     "start_time": "2022-01-13T09:18:58.782207Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d43433",
   "metadata": {},
   "source": [
    "# Help functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69b37a6",
   "metadata": {},
   "source": [
    "## Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15c67b12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T09:18:59.377725Z",
     "start_time": "2022-01-13T09:18:59.369579Z"
    }
   },
   "outputs": [],
   "source": [
    "def undersample(df, prop = 2):\n",
    "    \n",
    "    # get label 2\n",
    "    df2 = df[df[\"label\"]==2]\n",
    "    n2 = df2.shape[0]\n",
    "    \n",
    "    # get label 0\n",
    "    df0= df[df[\"label\"]==0]\n",
    "    df0 = df0.sample(frac=1)\n",
    "    \n",
    "    # sample from label 0\n",
    "    n0 = round(prop*n2)\n",
    "    df0_sample = df0.head(n0)\n",
    "    \n",
    "    # concatenate\n",
    "    df = pd.concat([df0_sample,df2], axis = 0)\n",
    "    df = df.sample(frac=1)\n",
    "    df.reset_index(inplace = True)\n",
    "    \n",
    "    assert(n0==prop*n2)\n",
    "    return df[[\"text\",\"score_punctuation\", \"score_capital_word\", \"label\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d508f26",
   "metadata": {},
   "source": [
    "## Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5297fb70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T09:18:59.711854Z",
     "start_time": "2022-01-13T09:18:59.705295Z"
    }
   },
   "outputs": [],
   "source": [
    "def oversample(df, prop = 0.3):# , seed = 123):\n",
    "    n = df.shape[0]\n",
    "    n2_new = round(prop*n) \n",
    "    \n",
    "    # get label 2\n",
    "    df2 = df[df[\"label\"]==2]\n",
    "    n2 = df2.shape[0]\n",
    "    n2_resample = n2_new - n2\n",
    "    if (n2_resample) < 0:\n",
    "        print(f\"WARNING: proportion {prop} already satisfied, DF unchanged\")\n",
    "    \n",
    "    else : \n",
    "        indices = list(range(n2))\n",
    "    \n",
    "        # resample from df2\n",
    "        indices_resample = resample(indices, replace=True, n_samples =n2_resample)#, random_state=f\"{seed}\")\n",
    "        df2_resample = df2.iloc[indices_resample]\n",
    "\n",
    "        df2_new = pd.concat([df2_resample, df2], axis =0)\n",
    "\n",
    "        df_new = pd.concat([df2_new, df[df[\"label\"]==0]], axis =0)\n",
    "        df = df_new\n",
    "    #assert(df2_new.shape[0]==prop*n)\n",
    "    df = df.sample(frac=1)\n",
    "    df.reset_index(inplace = True)\n",
    "    return df[[\"text\",\"score_punctuation\", \"score_capital_word\", \"label\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac73ea6e",
   "metadata": {},
   "source": [
    "## Data cleaning and tokenizing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3af859ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T09:19:00.095710Z",
     "start_time": "2022-01-13T09:19:00.089333Z"
    }
   },
   "outputs": [],
   "source": [
    "# # clean each tweet\n",
    "# def clean_data(data, remove_special_char_2lower_case = True):\n",
    "    \n",
    "#     #Removing URLs with a regular expression\n",
    "#     url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "#     data = url_pattern.sub(r'', data)\n",
    "\n",
    "#     # Remove Emails\n",
    "#     data = re.sub('\\S*@\\S*\\s?', '', data)\n",
    "   \n",
    "#     # tokenize + remove scpecial characters + set to lower case\n",
    "#     if remove_special_char_2lower_case == True:\n",
    "#         data = text_to_word_sequence(data) \n",
    "#     else :\n",
    "#     # tokenize \n",
    "#         data = data.split() \n",
    "    \n",
    "    \n",
    "#     # Remove stopwords\n",
    "#     stop_words = set(stopwords.words('english')) \n",
    "#     data = [w for w in data if not w in stop_words]         \n",
    "    \n",
    "#     # Remove digits\n",
    "#     data = ' '.join(word for word in data if not word.isdigit())\n",
    "    \n",
    "    \n",
    "#     return text_to_word_sequence(data)\n",
    "\n",
    "# # clean dataset\n",
    "# def apply_data_cleaning(X, text, drop_text = False, remove_special_char_2lower_case = True):\n",
    "#     ln = X.shape[0]\n",
    "#     sentences = []\n",
    "#     for i in range(ln):\n",
    "#         tmp = X.iloc[i][f'{text}']\n",
    "#         tmp_clean = clean_data(tmp,remove_special_char_2lower_case = f\"{remove_special_char_2lower_case}\")\n",
    "#         sentences.append(tmp_clean)\n",
    "#     X[\"sentences\"] = sentences\n",
    "#     if drop_text == True:\n",
    "#         X.drop(columns = f'{text}', inplace = True)\n",
    "#     return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48ad55d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T09:19:00.285096Z",
     "start_time": "2022-01-13T09:19:00.278848Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    \n",
    "    #Removing URLs with a regular expression\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    data = url_pattern.sub(r'', data)\n",
    "\n",
    "    # Remove Emails\n",
    "    data = re.sub('\\S*@\\S*\\s?', '', data)\n",
    "   \n",
    "    # tokenize + remove scpecial characters + set to lower case\n",
    "    data = text_to_word_sequence(data) \n",
    "    \n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    data = [w for w in data if not w in stop_words]         \n",
    "    \n",
    "    # Remove digits\n",
    "    data = ' '.join(word for word in data if not word.isdigit())\n",
    "    \n",
    "    \n",
    "    return text_to_word_sequence(data)\n",
    "\n",
    "def apply_data_cleaning(X, text, drop_text = False):\n",
    "    ln = X.shape[0]\n",
    "    sentences = []\n",
    "    for i in range(ln):\n",
    "       # print (f\"{i}\")\n",
    "        tmp = X.iloc[i][f'{text}']\n",
    "        tmp_clean = clean_data(tmp)\n",
    "        sentences.append(tmp_clean)\n",
    "    X[\"sentences\"] = sentences\n",
    "    if drop_text == True:\n",
    "        X.drop(columns = f'{text}', inplace = True)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c909fb53",
   "metadata": {},
   "source": [
    "## Help function for Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21cbc1bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T09:19:00.730252Z",
     "start_time": "2022-01-13T09:19:00.721103Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to convert a sentence (list of words) into a matrix representing the words in the embedding space\n",
    "def embed_sentence_with_TF(word2vec, sentence):\n",
    "    embedded_sentence = []\n",
    "    for word in sentence:\n",
    "        if word in word2vec:\n",
    "            embedded_sentence.append(word2vec[word])\n",
    "        \n",
    "    return np.array(embedded_sentence)\n",
    "\n",
    "# Function that converts a list of sentences into a list of matrices\n",
    "def embedding(word2vec, sentences):\n",
    "    embed = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        embedded_sentence = embed_sentence_with_TF(word2vec, sentence)\n",
    "        embed.append(embedded_sentence)\n",
    "        \n",
    "    return embed\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96b88e2",
   "metadata": {},
   "source": [
    "# Help function adding features to embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "476200f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T09:19:01.196685Z",
     "start_time": "2022-01-13T09:19:01.188251Z"
    }
   },
   "outputs": [],
   "source": [
    "def append_features_to_tensor(X_text, X_feature, _max ):\n",
    "\n",
    "    tmp = np.empty(shape=(X_text.shape[0],X_text.shape[1]+2, X_text.shape[2] ))\n",
    "    tmp[:,0:X_text.shape[1],:] = X_text\n",
    "\n",
    "    first_indices = X_text.shape[0] ## # of twitts \n",
    "    tmp_punct =  np.zeros(shape = (1,X_text.shape[2]))\n",
    "    tmp_cap = np.zeros(shape = (1,X_text.shape[2]))\n",
    "\n",
    "    for i in range(first_indices):\n",
    "        if X_feature.iloc[i,0] == 1:\n",
    "            tmp_punct =  tmp_punct*(_max+0.5)\n",
    "\n",
    "        if X_feature.iloc[i,1] == 1:\n",
    "            tmp_cap = tmp_cap*(_max+1)   \n",
    "\n",
    "        tmp[i,200,:] = tmp_punct\n",
    "        tmp[i,201,:] = tmp_cap\n",
    "\n",
    "    \n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba5b895",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63050ed",
   "metadata": {},
   "source": [
    "## Load re-labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "852722db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T09:19:02.387810Z",
     "start_time": "2022-01-13T09:19:02.031822Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('../raw_data/DF', 'rb') as handle:\n",
    "    DF = pickle.load(handle)\n",
    "DF.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6946bb7",
   "metadata": {},
   "source": [
    "## Undersample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e6cea58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T09:19:03.833010Z",
     "start_time": "2022-01-13T09:19:03.598660Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    90819\n",
       "2    10091\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = undersample(df= DF, prop = 9)\n",
    "df.shape\n",
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d31c95",
   "metadata": {},
   "source": [
    "## Oversample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d35ff30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T09:19:04.674166Z",
     "start_time": "2022-01-13T09:19:04.617931Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    90819\n",
       "2    30273\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = oversample(df =df , prop = 0.3 )#, seed = 123)\n",
    "df.shape\n",
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf97f55",
   "metadata": {},
   "source": [
    "## SubSampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67210a4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T09:19:05.573471Z",
     "start_time": "2022-01-13T09:19:05.571139Z"
    }
   },
   "outputs": [],
   "source": [
    "# N =100000\n",
    "# df = df.head(N)\n",
    "# df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61ae9f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T20:19:51.670017Z",
     "start_time": "2022-01-11T20:19:51.664240Z"
    }
   },
   "source": [
    "# Data split train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ef1d11f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T09:32:35.551583Z",
     "start_time": "2022-01-13T09:32:35.503693Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split in X, y\n",
    "X = df.copy() \n",
    "X.drop(columns = \"label\", inplace = True)\n",
    "y = df[\"label\"]\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state=42)\n",
    "assert(len(X_train)==len(y_train))\n",
    "assert(len(X_test)==len(y_test))\n",
    "assert(len(X_train)+len(X_test)==X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0bfc4f22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T09:32:35.652958Z",
     "start_time": "2022-01-13T09:32:35.647524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121092\n",
      "96873\n",
      "24219\n"
     ]
    }
   ],
   "source": [
    "print(len(y))\n",
    "print(len(y_train))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ec7399f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T09:32:35.932885Z",
     "start_time": "2022-01-13T09:32:35.926206Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121092, 3)\n",
      "(96873, 3)\n",
      "(24219, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c27ea20a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T09:32:36.130059Z",
     "start_time": "2022-01-13T09:32:36.089323Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split X into text and features\n",
    "X_train_text = X_train[[\"text\"]]\n",
    "X_test_text = X_test[[\"text\"]]\n",
    "\n",
    "X_train_features = X_train[[\"score_punctuation\", \"score_capital_word\"]]\n",
    "X_test_features = X_test[[\"score_punctuation\", \"score_capital_word\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9dfc9b09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T09:32:36.367985Z",
     "start_time": "2022-01-13T09:32:36.361982Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96873\n",
      "24219\n",
      "(96873, 1)\n",
      "(96873, 2)\n",
      "(24219, 1)\n",
      "(24219, 2)\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train))\n",
    "print(len(y_test))\n",
    "\n",
    "print(X_train_text.shape)\n",
    "print(X_train_features.shape)\n",
    "\n",
    "print(X_test_text.shape)\n",
    "print(X_test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9b84641d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T09:32:36.571910Z",
     "start_time": "2022-01-13T09:32:36.556940Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>score_punctuation</th>\n",
       "      <th>score_capital_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4107</th>\n",
       "      <td>Some old hag just tried to talk my ear off abo...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105343</th>\n",
       "      <td>Likewise,I feel the need to thank  for the cou...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68188</th>\n",
       "      <td>Can’t even a do a  scandal properly...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29054</th>\n",
       "      <td>This pic is why this show should be the poster...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75894</th>\n",
       "      <td>Help to Stop the Pain of Physically &amp;amp; Sexu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  score_punctuation  \\\n",
       "4107    Some old hag just tried to talk my ear off abo...                  0   \n",
       "105343  Likewise,I feel the need to thank  for the cou...                  0   \n",
       "68188              Can’t even a do a  scandal properly...                  0   \n",
       "29054   This pic is why this show should be the poster...                  0   \n",
       "75894   Help to Stop the Pain of Physically &amp; Sexu...                  0   \n",
       "\n",
       "        score_capital_word  \n",
       "4107                     1  \n",
       "105343                   0  \n",
       "68188                    0  \n",
       "29054                    0  \n",
       "75894                    0  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8424dcd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T09:32:36.753604Z",
     "start_time": "2022-01-13T09:32:36.737167Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>score_punctuation</th>\n",
       "      <th>score_capital_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87293</th>\n",
       "      <td>Are the Dems investigating any of the sexual a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79255</th>\n",
       "      <td>The  movement needs to address the phenomenon ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63152</th>\n",
       "      <td>\\n doesn't matter to women abused by Democrat...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64647</th>\n",
       "      <td>while he was choking her out? I get what you...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79037</th>\n",
       "      <td>This is so true and  looked foolish making the...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  score_punctuation  \\\n",
       "87293  Are the Dems investigating any of the sexual a...                  0   \n",
       "79255  The  movement needs to address the phenomenon ...                  0   \n",
       "63152   \\n doesn't matter to women abused by Democrat...                  0   \n",
       "64647    while he was choking her out? I get what you...                  0   \n",
       "79037  This is so true and  looked foolish making the...                  0   \n",
       "\n",
       "       score_capital_word  \n",
       "87293                   0  \n",
       "79255                   0  \n",
       "63152                   0  \n",
       "64647                   1  \n",
       "79037                   0  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9253cf99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T21:11:24.757485Z",
     "start_time": "2022-01-11T21:11:24.748902Z"
    }
   },
   "source": [
    "# Clean and tokenize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee2000a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T09:32:57.006100Z",
     "start_time": "2022-01-13T09:32:37.237645Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(X_text.head())\n",
    "X_train_text = apply_data_cleaning(X = X_train_text, text = \"text\",drop_text = True)#, remove_special_char_2lower_case = True)\n",
    "X_test_text = apply_data_cleaning(X = X_test_text, text = \"text\", drop_text = True)#, remove_special_char_2lower_case = True)\n",
    "\n",
    "X_train_text = list(X_train_text.sentences)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_test_text = list(X_test_text.sentences)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "assert(len(X_train_text)==len(y_train))\n",
    "assert(len(X_test_text)==len(y_test))\n",
    "assert(X_train_features.shape[0]==len(y_train))\n",
    "assert(X_test_features.shape[0])==len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "eb453ffa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T09:31:32.608995Z",
     "start_time": "2022-01-13T09:31:32.601488Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96873\n",
      "24219\n",
      "96873\n",
      "(96873, 2)\n",
      "24219\n",
      "(24219, 2)\n"
     ]
    }
   ],
   "source": [
    "# print(len(y_train))\n",
    "# print(len(y_test))\n",
    "\n",
    "# print(len(X_train_text))\n",
    "# print(X_train_features.shape)\n",
    "\n",
    "# print(len(X_test_text))\n",
    "# print(X_test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9417196f",
   "metadata": {},
   "source": [
    "# Save cleaned and tokenized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "aa8fb4b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T09:34:28.426885Z",
     "start_time": "2022-01-13T09:34:27.965022Z"
    }
   },
   "outputs": [],
   "source": [
    "# X_train\n",
    "with open('../raw_data/X_train_text', 'wb') as f1:\n",
    "    pickle.dump(X_train_text, f1)\n",
    "with open('../raw_data/X_train_features', 'wb') as f1:\n",
    "    pickle.dump(X_train_features, f1)\n",
    "\n",
    "# X_test\n",
    "with open('../raw_data/X_test_text', 'wb') as f1:\n",
    "    pickle.dump(X_test_text, f1)   \n",
    "with open('../raw_data/X_test_features', 'wb') as f1:\n",
    "    pickle.dump(X_test_features, f1)       \n",
    "\n",
    "# y_train\n",
    "with open('../raw_data/y_train', 'wb') as f1:\n",
    "    pickle.dump(y_train, f1)\n",
    "    \n",
    "# y_test2\n",
    "with open('../raw_data/y_test', 'wb') as f1:\n",
    "    pickle.dump(y_test, f1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aaa9dced",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T09:26:45.832689Z",
     "start_time": "2022-01-13T09:26:45.827194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121092\n",
      "96873\n",
      "(96873, 2)\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train))\n",
    "print(len(X_train_text))\n",
    "print(X_train_features.shape)\n",
    "\n",
    "# print(len(y_test))\n",
    "# print(len(X_test_text))\n",
    "# print(X_test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a56f308",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T21:25:31.541945Z",
     "start_time": "2022-01-11T21:25:31.516103Z"
    }
   },
   "source": [
    "# Embedding TF\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dd0543",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T09:06:47.610613Z",
     "start_time": "2022-01-13T09:06:47.608098Z"
    }
   },
   "outputs": [],
   "source": [
    "#print(list(api.info()['models'].keys()))\n",
    "ll = ['fasttext-wiki-news-subwords-300',\n",
    " 'conceptnet-numberbatch-17-06-300', \n",
    " 'word2vec-ruscorpora-300', \n",
    " 'word2vec-google-news-300', \n",
    " 'glove-wiki-gigaword-50', \n",
    " 'glove-wiki-gigaword-100',\n",
    " 'glove-wiki-gigaword-200', \n",
    " 'glove-wiki-gigaword-300', \n",
    " 'glove-twitter-25', \n",
    " 'glove-twitter-50', \n",
    " 'glove-twitter-100', \n",
    " 'glove-twitter-200', \n",
    " '__testing_word2vec-matrix-synopsis']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8bf12a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-01-13T09:10:28.262Z"
    }
   },
   "outputs": [],
   "source": [
    "#print(list(api.info()['models'].keys()))\n",
    "word2vec_transfimporer = api.load('glove-twitter-50')\n",
    "\n",
    "# Embed the training and test sentences\n",
    "X_train_embed_tf = embedding(word2vec_transfer, X_train_text)\n",
    "X_test_embed_tf = embedding(word2vec_transfer, X_test_text)\n",
    "\n",
    "# Pad the training and test embedded sentences\n",
    "X_train_pad = pad_sequences(X_train_embed_tf, dtype='float32', padding='post', maxlen=200)\n",
    "X_test_pad = pad_sequences(X_test_embed_tf, dtype='float32', padding='post', maxlen=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b9e743",
   "metadata": {},
   "source": [
    "## Pickle and save embedded data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9778daab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T14:51:12.402400Z",
     "start_time": "2022-01-12T14:51:12.395187Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(y_train))\n",
    "print(len(y_test))\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b482999",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T14:51:12.420853Z",
     "start_time": "2022-01-12T14:51:12.404648Z"
    }
   },
   "outputs": [],
   "source": [
    "# X_train\n",
    "with open('../raw_data/X_train_pad', 'wb') as f1:\n",
    "    pickle.dump(X_train_pad, f1)\n",
    "    \n",
    "# X_test\n",
    "with open('../raw_data/X_test_pad', 'wb') as f1:\n",
    "    pickle.dump(X_test_pad, f1)   \n",
    "    \n",
    "\n",
    "# y_train\n",
    "with open('../raw_data/y_train', 'wb') as f1:\n",
    "    pickle.dump(y_train, f1)\n",
    "    \n",
    "# y_test2\n",
    "with open('../raw_data/y_test', 'wb') as f1:\n",
    "    pickle.dump(y_test, f1)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c3d0bf",
   "metadata": {},
   "source": [
    "# Add features to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da415f26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T14:51:12.513268Z",
     "start_time": "2022-01-12T14:51:12.504311Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_pad_added_features = append_features_to_tensor(X_train_pad, \\\n",
    "                                                       X_feature = X_train_features, \\\n",
    "                                                       _max = X_train_pad.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c8f2bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T14:51:12.518953Z",
     "start_time": "2022-01-12T14:51:12.514523Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test_pad_added_features = append_features_to_tensor(X_test_pad, \\\n",
    "                                                       X_feature = X_test_features, \\\n",
    "                                                       _max = X_test_pad.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61000c3b",
   "metadata": {},
   "source": [
    "# Pickle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a89a15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cba5fc1",
   "metadata": {},
   "source": [
    "# Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627b00d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T14:51:12.733464Z",
     "start_time": "2022-01-12T14:51:12.521345Z"
    }
   },
   "outputs": [],
   "source": [
    "def init_model():\n",
    "    model = Sequential()\n",
    "    model.add(layers.Masking())#, label =\"layer1_masking\")\n",
    "    model.add(layers.LSTM(20, activation='tanh'))#, label =\"layer2_LSTM\")\n",
    "    model.add(layers.Dense(15, activation='relu'))#, label =\"layer3_dense_relu\")\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))#, label =\"layer4_dense_sigmoid\")\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=[\"Recall\"]) #['recall']) # tp/(tp+fn) metrics=[tf.keras.metrics.Recall()]\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = init_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344a924c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T14:51:19.233118Z",
     "start_time": "2022-01-12T14:51:12.735028Z"
    }
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "#%%time\n",
    "history = model.fit(X_train_pad, y_train, \n",
    "          batch_size = 32,  # low --> optimizes on smaller ss --> faster --> but to generalize \n",
    "          epochs=10,\n",
    "          validation_split=0.3,\n",
    "          callbacks=[es]\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ed36f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T14:51:19.242881Z",
     "start_time": "2022-01-12T14:51:19.234952Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_loss_recall(history, title=None):\n",
    "    fig, ax = plt.subplots(1,2, figsize=(20,7))\n",
    "    \n",
    "    # --- LOSS --- \n",
    "    \n",
    "    ax[0].plot(history.history['loss'])\n",
    "    ax[0].plot(history.history['val_loss'])\n",
    "    ax[0].set_title('Model loss')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "    ax[0].set_ylim((0,3))\n",
    "    ax[0].legend(['Train', 'Test'], loc='best')\n",
    "    ax[0].grid(axis=\"x\",linewidth=0.5)\n",
    "    ax[0].grid(axis=\"y\",linewidth=0.5)\n",
    "    \n",
    "    # --- ACCURACY\n",
    "    \n",
    "    ax[1].plot(history.history['recall'])\n",
    "    ax[1].plot(history.history['val_recall'])\n",
    "    ax[1].set_title('Model Recall')\n",
    "    ax[1].set_ylabel('recall')\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "    ax[1].legend(['Train', 'Test'], loc='best')\n",
    "    ax[1].set_ylim((0,1))\n",
    "    ax[1].grid(axis=\"x\",linewidth=0.5)\n",
    "    ax[1].grid(axis=\"y\",linewidth=0.5)\n",
    "    \n",
    "    if title:\n",
    "        fig.suptitle(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222a5ddc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T14:51:19.718879Z",
     "start_time": "2022-01-12T14:51:19.244561Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_loss_recall(model.history, title=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587b808d",
   "metadata": {},
   "source": [
    "## Select epoch and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fc62cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T14:51:19.729023Z",
     "start_time": "2022-01-12T14:51:19.723503Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "# filepath = './saved_model'\n",
    "# save_model(model, filepath)\n",
    "# model = load_model(filepath, compile = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847839fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T14:52:01.914158Z",
     "start_time": "2022-01-12T14:51:56.574994Z"
    }
   },
   "outputs": [],
   "source": [
    "model = init_model()\n",
    "model.fit(X_train_pad, y_train, \n",
    "          batch_size = 32,  # low --> optimizes on smaller ss --> faster --> but to generalize \n",
    "          epochs=10,\n",
    "          validation_split=0.3#,\n",
    "        #  callbacks=[es]\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7915077b",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f06f30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T14:54:00.494405Z",
     "start_time": "2022-01-12T14:54:00.330461Z"
    }
   },
   "outputs": [],
   "source": [
    "! ls ../project_BAN/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdeb6c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T14:54:07.608981Z",
     "start_time": "2022-01-12T14:54:03.917125Z"
    }
   },
   "outputs": [],
   "source": [
    "models.save_model(model, '../project_BAN/models/model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1a7164",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1959a0df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T15:01:09.442064Z",
     "start_time": "2022-01-12T15:01:07.283254Z"
    }
   },
   "outputs": [],
   "source": [
    "loaded_model = models.load_model('../project_BAN/models/model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136fd14f",
   "metadata": {},
   "source": [
    "# Predict from tweet - test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d7a0c8",
   "metadata": {},
   "source": [
    "### Prediction time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cd37d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5e4b67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T14:44:45.115240Z",
     "start_time": "2022-01-12T14:44:45.083407Z"
    }
   },
   "outputs": [],
   "source": [
    "# write tweet\n",
    "tweet = \"I love deep learning\"\n",
    "\n",
    "score_punctuation = ponctuation_check(tweet)\n",
    "score_capitalization = capital_word_check(tweet)\n",
    "\n",
    "tweet_tokenized = clean_data(tweet)\n",
    "tweet_tokenized\n",
    "\n",
    "tweet_emebedded = embed_sentence_with_TF(word2vec_transfer, tweet_tokenized)\n",
    "tweet_emebedded_reshape  = tweet_emebedded.reshape((1,tweet_emebedded.shape[0], tweet_emebedded.shape[1]))\n",
    "\n",
    "res = loaded_model.predict(tweet_reshape)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62662bf7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T14:44:36.946229Z",
     "start_time": "2022-01-12T14:44:36.946209Z"
    }
   },
   "outputs": [],
   "source": [
    "if res[0][0]< 0.5:\n",
    "    print(\"good tweet\")\n",
    "else:\n",
    "    print(\"hate tweet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73f6e44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T08:19:48.084533Z",
     "start_time": "2022-01-13T08:19:00.680428Z"
    }
   },
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "import pickle\n",
    "word2vec_transfimporer = api.load('glove-twitter-50')\n",
    "with open('../project_BAN/models/word2vec_transfer', 'wb') as f1:\n",
    "    pickle.dump(word2vec_transfer, f1, protocol = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f033fcf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T08:20:25.125233Z",
     "start_time": "2022-01-13T08:20:23.088112Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('../project_BAN/models/word2vec_transfer', 'wb') as f1:\n",
    "    pickle.dump(word2vec_transfer, f1, protocol = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2f5521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../project_BAN/models/word2vec_transfer', 'rb') as handle:\n",
    "   #     word2vec_transfer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fce283",
   "metadata": {},
   "source": [
    "# To do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c1d642",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T08:59:14.079362Z",
     "start_time": "2022-01-13T08:59:14.070557Z"
    }
   },
   "source": [
    "- Replace emojis by text in traning data\n",
    "\n",
    "- Prep data upto embedding and pickle  \n",
    "\n",
    "------ new jn ----------------\n",
    "- import pickled data + add features\n",
    "- save as pickle\n",
    "\n",
    "------------ new jn ------------------\n",
    "run models \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba6bf92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "625.455px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
