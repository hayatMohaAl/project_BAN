{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3a50088",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "b6ec3b86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T10:02:12.472381Z",
     "start_time": "2022-01-07T10:02:12.457784Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import string \n",
    "import re\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "# import nltk\n",
    "# from nltk.corpus import wordnet\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "# #from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
    "#from nltk.corpus import stopwords\n",
    "\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import spacy\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import Sequential, layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "print('Done')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38fd5ba",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "99708015",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:24:56.109255Z",
     "start_time": "2022-01-07T09:24:52.849757Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', None) \n",
    "df = pd.read_csv(\"~/Downloads/banData/MeTooHate.csv\")[[\"text\", \"category\"]]\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a9feed",
   "metadata": {},
   "source": [
    "## Undersample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e49f49e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:24:56.646960Z",
     "start_time": "2022-01-07T09:24:56.114770Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = df[df[\"category\"]== 1]\n",
    "df1 = df[df[\"category\"]== 1].dropna()\n",
    "df0 = df[df[\"category\"]== 0].dropna()\n",
    "df = pd.concat([df0.sample(df1.shape[0]), df1], axis = 0)\n",
    "\n",
    "\n",
    "#shuffle rows\n",
    "df = df.sample(frac=1)\n",
    "df.shape\n",
    "df.reset_index(inplace = True)\n",
    "\n",
    "df = df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d571bb3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:24:56.666567Z",
     "start_time": "2022-01-07T09:24:56.649026Z"
    }
   },
   "outputs": [],
   "source": [
    "y = df[\"category\"]\n",
    "X = df.drop(columns = [\"category\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "97ad4491",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:24:56.685226Z",
     "start_time": "2022-01-07T09:24:56.679852Z"
    }
   },
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289ed67c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T15:49:20.415916Z",
     "start_time": "2022-01-06T15:49:20.408766Z"
    }
   },
   "source": [
    "## Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ccb77746",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:24:56.756889Z",
     "start_time": "2022-01-07T09:24:56.693096Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    \n",
    "    #Removing URLs with a regular expression\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    data = url_pattern.sub(r'', data)\n",
    "\n",
    "    # Remove Emails\n",
    "    data = re.sub('\\S*@\\S*\\s?', '', data)\n",
    "   \n",
    "    # tokenize + remove scpecial characters + set to lower case\n",
    "    data = text_to_word_sequence(data) \n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    data = [w for w in data if not w in stop_words]         \n",
    "    \n",
    "    # Remove digits\n",
    "    data = ' '.join(word for word in data if not word.isdigit())\n",
    "    \n",
    "    \n",
    "    return text_to_word_sequence(data)\n",
    "\n",
    "def apply_data_cleaning(X, text, drop_text = False):\n",
    "    ln = X.shape[0]\n",
    "    sentences = []\n",
    "    for i in range(ln):\n",
    "        tmp = X.iloc[i][f'{text}']\n",
    "        tmp_clean = clean_data(tmp)\n",
    "        sentences.append(tmp_clean)\n",
    "    X[\"sentences\"] = sentences\n",
    "    if drop_text == True:\n",
    "        X.drop(columns = f'{text}', inplace = True)\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "7d02b329",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:24:56.820548Z",
     "start_time": "2022-01-07T09:24:56.762278Z"
    }
   },
   "outputs": [],
   "source": [
    "X = apply_data_cleaning(X = X, text = \"text\", drop_text = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0667df0",
   "metadata": {},
   "source": [
    "## Train-Test split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "772be889",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:24:56.838855Z",
     "start_time": "2022-01-07T09:24:56.825168Z"
    }
   },
   "outputs": [],
   "source": [
    "X = list(X.sentences)\n",
    "y = np.array(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "# print(len(X_train))\n",
    "# print(len(y_train))\n",
    "# print(len(X_test))\n",
    "# print(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e55147",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Tokenize  data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a487c622",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:23:49.983659Z",
     "start_time": "2022-01-07T09:23:49.974192Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Initializes a Keras utilities that does all the tokenization for you\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "# The tokenization learns a dictionnary that maps a token (integer) to each word\n",
    "# It can be done only on the train set - we are not supposed to know the test set !\n",
    "# This tokenization also lower your words, apply some filters, and so on - you can check the doc if you want\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "    \n",
    "# We apply the tokenization to the train and test set\n",
    "X_train_token = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_token = tokenizer.texts_to_sequences(X_test)\n",
    "#X_test_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "bc726231",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:23:50.949015Z",
     "start_time": "2022-01-07T09:23:50.945819Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## sjekk\n",
    "# sentence_number = 10\n",
    "\n",
    "# input_raw = X_train[sentence_number]\n",
    "# input_token = X_train_token[sentence_number]\n",
    "# for i in range(2):\n",
    "#     print(f'Word : {input_raw[i]} -> Token {input_token[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5567244b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T21:27:42.019998Z",
     "start_time": "2022-01-06T21:27:42.013444Z"
    },
    "hidden": true
   },
   "source": [
    "### Add vocabulary\n",
    "\n",
    "The dictionary that maps each word to a token can be accessed with `tokenizer.word_index`\n",
    "    \n",
    "Add a `vocab_size` variable that stores the number of different words (=tokens) in the train set. This is called the _size of the vocabulary_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e5e493d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:23:51.818897Z",
     "start_time": "2022-01-07T09:23:51.812525Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 737 different words in the train set\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index)\n",
    "\n",
    "print(f'There are {vocab_size} different words in the train set')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec81718",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Padding\n",
    "_filling_ cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e30d39c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:23:52.864722Z",
     "start_time": "2022-01-07T09:23:52.858800Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train_pad = pad_sequences(X_train_token, dtype='float32', padding='post')\n",
    "X_test_pad = pad_sequences(X_test_token, dtype='float32', padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7609ec",
   "metadata": {
    "hidden": true
   },
   "source": [
    "!set maxlen <<< lower than longest sentence for efficiency/wt loss info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ed47617d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:23:59.018142Z",
     "start_time": "2022-01-07T09:23:58.683910Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAc8AAAEICAYAAAA5lX8nAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAbVElEQVR4nO3debglVXnv8e8LzQwyhCMy2DROKBjj0IrTVSIODBrUoEKigkNQExUcriIxEQ1eMXG811wRh4CKIA+CciU3SlRAI6DdiAg0igLaQEM3QwdaiIq8+WOtA9Xbs0+f1X26d+/i+3me85y9d9WuelcN61dVu84+kZlIkqSZ22DUBUiSNG4MT0mSGhmekiQ1MjwlSWpkeEqS1MjwlCSp0ayEZ0RcHhF7z8a0xlVEvCgiFkfEioh43AzG3zsirlsXtc2miDgsIr43wvm/ISJuqsv5j0ZVxziJiHkRkRExZy1Nf6TbxNrQ9z4tIo6JiC+OcP7HRsTNEXHjCGtYo/1ileEZEddGxLMHXltpZ8nMPTPz3LVZ6Bj4EPDGzNwyM380OLC2/WEjqKs3ImIj4CPAc+tyvmUdzffciHjtupjXbJhqn13D6d3vtt2Z9GlaPRExF3gbsEdmPmjU9ayu3ly2XQ9CeVfg8hHXMFZWY53tAGyKy1lab6zGfjwXuCUzl66NeqayVvIhM6f9Aa4Fnj3w2mHA96YaB3gSsAC4HbgJ+Eh9/VdAAivqz1Mo4f1u4JfAUuDzwNad6b6yDrsF+LuB+RwDnA58sc7rtXXeFwDLgSXAJ4CNO9NL4K+Bq4A7gH8AHgp8v07jtO74A22eslZgk9qeBH4N/GKK957fGb4CeBmwN3Ad5Qhsaa33VZ33bEI5m/1VXY7HA5sNqe0w4Ht1/NuAa4D9hq3Duuy+WB/Pq7W9Clhc3/964InApXVZfmJgXv9Rl+1/AlcC+3SGbw18trbneuBYYMOB9360rtNjp2jLJsDHgBvqz8fqa4+oy29yG/r2FO/dtG4Pt9S6fwjsMMO6plx+wPuB3wP/Vef7ifr6I4FzgFuBnwIv7dRxIvDPwNmU7ewi4KGd4Xt23nsTcHRnGzsK+EVtw2nAdqtq28Ay+AJwD3BXrfcdnXV8KGV7uhn42857hu43TLHtrsb29ypgUV0WVwOv6wxbBDy/83wOsAx4fH3+ZMr+uRz4MbD3NH3V5LK7A7gCeNE0424GnFTrXVSX03WD+wywU12W23WGPa4uw43q81fXadwGfAPYdaDPeT2lz1let4sYUtMxdZ1/vrbhcmD+wLQeNrCdHVsf703pT97Bff3JC4H9gZ9RtrWjB+Z1OvDlOq+LgT/pDN8J+EpdF9cAb57ivff2vVO0ZevajmWUPvPdlO372XV53lO3pxOneO95wJ/Xx0+r7T6gPt8HuGS6PnmgX3sNZZs/H9iQso3eTNkO/6aOM6ezHV9dl8c1wF8O234yc62E5wXAK+rjLYEnDzRmTud9rwZ+DjykjnsG8IU6bI+6cJ8ObFwb/TtWDs/f1Q1kA8rO8ATKzjanzm8RcOTAxvc14AGUDuw3wLfq/Lem7HCHDlkOQ2udasOe4v2DG/7ewN3A+4CNKBv5ncC2dfhHgbOA7YCtgP8HfGDItA+ry+Kv6gbyBkrwxFTrkKnD83hKB/1cSlB8FXggsDNlw3xmZ153A2+pdb+MEqKTnfyZwKeALer7f0DtLDvvfVNdR39wMFCXx4X1vROUjvMfhm1DA+99XV1Om9fl8ATgATOsa7rldy6dDqJOYzElFOZwX2e6R6dTu4USSnOAk4FT67CtKB3b2+ry3grYqw47orZ9F8oBw6eAU1bVtlXts53l9mnKfvInlG3/UXX4TPab6bbtVS2/AygHqQE8k7KdT4bj3wMnd6Z1ALCoPt65Lsf9Kfv4c+rziSF1vITS6W9A2S5/Dew4ZNzjKJ30tnV5X8oU4Vkffxv4q86wfwKOr48PpPQLj6rL793A9weW3deBbShnXMuAfYfUdAxl39u/LscPABdO04ecyMrheXddnhvVdbEM+BJlG9uTElq7DfSfB9Xx304JjI3q8ltYp7Uxpc+7GnjesL53irZ8ntLXbkXZpn4GvKZT63VTLYNOH/B/6uOjKQdEH+wM+/gM8mNeXV6fp+yvm1EOYq4EHkzpV79Tx5lTx7kd2L2+f0dgz2E1Zs48PFdQjpomf+5keHieD7wX2H5gOpON6Ybnt4C/7jzfva6UOXXFndIZtjnwW1YOz/NXUfuRwJkDG9/TOs8XAu/sPP8w8LEh0xpa6ww7mKnC866B5bGU0okFZcfvnq08Bbhmms7r5wPLKoEHDa6fzrIbDM+dO8NvoXOGQTkCPbIzr3s7xvraD4BXUC6r/obOzgQcAnyn895frWKd/QLYv/P8ecC1w7ahgfe+mhK2jxl4fSZ1Tbf8zmXl8HwZ8N2BeXwKeE99fCLwmc6w/YErO/P90ZD6F7HyWfyO3Lc/TNm2afbZqcJzl4F1dnDDfrOq8By6/KYY/6vAEfXxwyhH+pvX5ycDf18fv5POAWp97RsMOcCdYj6XAAcOGXZvGNTnr2V4eL6WeqWDsm8uBp5Rn/9/aijU5xtQ+sddO8vu6Z3hpwFHDanpGODfO8/3AO4ath74w/C8i/uupmxVx9+rM/5C4IWdeV04UPcS4H8AezGwnwLvAv6l896hfS8l+H9LPZisr70OOLdT63ThuQ9waX38b3X5X1ifnwe8uD6eLj/m1fY/pDP828DrO8+fy8rhuRz4c4Zc4Rv8melnni/MzG0mfyiXPod5DeUS25UR8cOIeP404+5EOeWe9MvakB3qsMWTAzLzTkqn3rW4+yQiHhERX4+IGyPiduB/AdsPvOemzuO7pni+5WrUurpuycy7O8/vrPOfoHRACyNieUQsp2xEE9NM69671uqyguFtmUrLcrk+69ZX/ZKyfHalHLku6dT9KcqZ3qSV1tkUplrOO82kAZRLlt8ATo2IGyLiH+tNRjOpq2X57QrsNTmtOr2/BLo3P3TvIpxcr1COen8xzXTP7ExzEeWS8Q7TtK3FlDXNcL+Z8bQHl19E7BcRF0bErbVd+09OPzN/Xtv5gojYHPgzytkSlOXxkoHl/HTKQcUfiIhXRsQlnXEfPU07VupfmH67/ArwlIjYEXgG5ZLjdzs1frwzz1spAbtz5/3DtoWpDI67acPndbdk5u/r47vq7+n2427/eg/lsu/kfrzTwHI/mpX7uumW1/aU/W1wP9556tH/wAXAIyJiB+CxlLPHB0fE9pSrOefX8WbSJ3frHFzn9743M39NOSh+PaWfODsiHjldkbN+w1BmXpWZh1A6pg8Cp0fEFpSEH3QDZUVNmku59HAT5Shol8kBEbEZMPinCYPT/CTltPzhmfkAygqP1W/NjGudbTdTNvQ9OwctW2dmSxh2/ZoSxpPW9A63nSOiu1znUpbPYsoZ3vaduh+QmXt2xp1qO+iaajnfMJOiMvN3mfnezNwDeCrwfMrn5jOpa9pJDzxfDJzXPaDMcvfvG2YwrcWUy0zDhu03MN1NM/P6ado2k3pXZa3tNxGxCSV8PkT5jHYb4F8Hpn8K5Yz8QOCKGqhQlscXBpbHFpl53BTz2ZVyWfqNwB/V+Vw2TTtW6l8oBzVTyszbgG9SOte/oFyCn1zGiymX/7s1bpaZ3x82vTVwJ7O7H9/b5ojYgLI8JvfjawbatFVm7t9573Tb2M2UM8DB/fj6mRRVD74WUj7GuCwzf0u56vJWyj0lN9dRZ9Ind+tcwsrree7AfL+Rmc+hHJxdSdmehpr18IyIl0fERD2SWV5fvody/f0eVu44TgHeEhG7RcSWlCPeL9ezsdMpR6NPjYiNKZcKVrVDb0W5br2iHjXMpDObqelqnYmbGN5prqQuu08DH42IBwJExM4R8bzVqBvK5auDI2KjiJhP+ZxjTTwQeHOd3kson/f8a2YuoXQyH46IB0TEBhHx0Ih4ZsO0TwHeHRET9Ujz7yk3JqxSRPxpRPxxRGxI2Q5+B9wzC3UNrruvU46MX1GXwUYR8cSIeNQMpvV1YMeIODIiNomIrSJirzrseOD9NQioy+DA6do2w3pXZVX7Tev0ujamfH67DLg7IvajXC7rOrW+9gbuO+uEst5fEBHPi4gNI2LTKH8fvQt/aPIAfRlARLyKcuY5zGnAuyJi24jYmRK60/kS5WDloIEaj6/T2bPOd+u6T6wNlwB/UZfFvpTPj9fEEyLixfXM9kjKAeaFlEv6d0TEOyNiszq/R0fEE2cy0Xr2explW96qbs9vZYb7cXUeZZ2cV5+fO/Ac2vvk0yj91i4RsS3lBjMAImKHiDiwnuj9hvJR5bD9C1g7f6qyL3B5RKwAPk75XOWuejTxfuA/6qWAJwOfo1yOOp/yYfV/UW4mITMvr49PpRwxrKB8Jvibaeb9dsqR4R2U8PnyLLZraK0zdAxwUm37S2cw/jspH4ZfWC+l/Tvlmv7q+DvKDRu3UT6P/tL0o6/SRcDDKUeY7wcOyvv+5vKVlA7zijq/0xlymW2IYyl3a18K/IRyF+CxM3zvg+r8bqdcCjyPss7WtK6PAwdFxG0R8b8z8w5KZ38w5ej3RspVlk1WNaH63ucAL6jvuwr40858zgK+GRF3UDqyyWCdrm2DPkA5AFkeEW+fQftWtd8cQ9u2e6/a3jdTOq7b6nzOGhhnCeVS3VO7887MxZSz0aMpobgY+J9M0W9l5hWUexYuoIT9H1Pu7B7mfZTLlNdQ9q3Tmb5vOYuyzd+YmT/uzPdMyro/te6nlwH7TTOdNXEEZbtZTvmY4KtrOL2vUc6mb6Pcs/DieoXj95QrG4+lLJ+bgc9QbqqcqTdRrnhdTbkT+0uUPnSmzqMc1J0/5Dm098mfpnz08WNKv3JGZ9gGlIC/gXLp/Zms4uRr8m649V49slhOubR0zYjLkdQjEfEGyoH+mp7N6X5ivf6ShIh4QURsXk+lP0Q5E7l2tFVJGncRsWNEPK1ewt+d8qdDZ466Lo2P9To8KZdsJv9Y/uGUI8PxOFWWtD7bmHLH9R2UP2H4GvB/R1qRxsrYXLaVJGl9sb6feUqStN4Z9Zeprxe23377nDdv3qjLkKSxsXDhwpszc7ovbuk1wxOYN28eCxYsGHUZkjQ2IuKXqx6rv7xsK0lSI8NTkqRGhqckSY0MT0mSGhmekiQ1MjwlSWo0tuEZEZ+LiKURcVnntX+KiCsj4tKIODMithlhiZKknhrb8AROpPz7s65zgEdn5mOAnwHvWtdFSZL6b2zDMzPPp/zfte5r3+z8I9QLWfk/xUuSNCv6/A1Dr2aaf4YdEYcDhwPMnTt3XdU0a+YddfaoS1jnrj3ugFGXoHVgVNu225dajO2Z53Qi4m+Bu4GTh42TmSdk5vzMnD8xcb/9ekZJ0mro3ZlnRBwGPB/Yx//9KUlaG3oVnhGxL/AO4JmZeeeo65Ek9dPYXraNiFOAC4DdI+K6iHgN8AlgK+CciLgkIo4faZGSpF4a2zPPzDxkipc/u84LkSTd74ztmackSaNieEqS1MjwlCSpkeEpSVIjw1OSpEaGpyRJjQxPSZIaGZ6SJDUyPCVJamR4SpLUyPCUJKmR4SlJUiPDU5KkRoanJEmNDE9JkhoZnpIkNTI8JUlqZHhKktTI8JQkqZHhKUlSI8NTkqRGhqckSY0MT0mSGhmekiQ1MjwlSWo0tuEZEZ+LiKURcVnnte0i4pyIuKr+3naUNUqS+mlswxM4Edh34LWjgG9l5sOBb9XnkiTNqrENz8w8H7h14OUDgZPq45OAF67LmiRJ9w9zRl3ALNshM5fUxzcCOwwbMSIOBw4HmDt37jooTWtq3lFnj2ze1x53wMjmLWn9M7ZnnquSmQnkNMNPyMz5mTl/YmJiHVYmSRp3fQvPmyJiR4D6e+mI65Ek9VDfwvMs4ND6+FDgayOsRZLUU2MbnhFxCnABsHtEXBcRrwGOA54TEVcBz67PJUmaVWN7w1BmHjJk0D7rtBBJ0v3O2J55SpI0KoanJEmNDE9JkhoZnpIkNTI8JUlqZHhKktTI8JQkqZHhKUlSI8NTkqRGhqckSY0MT0mSGo3td9uuL0b5D5rVf6Pavvzn39L0PPOUJKmR4SlJUiPDU5KkRoanJEmNDE9JkhoZnpIkNTI8JUlqZHhKktTI8JQkqZHhKUlSI8NTkqRGhqckSY0MT0mSGhmekiQ16mV4RsRbIuLyiLgsIk6JiE1HXZMkqT96F54RsTPwZmB+Zj4a2BA4eLRVSZL6pHfhWc0BNouIOcDmwA0jrkeS1CO9C8/MvB74EPArYAnwn5n5zcHxIuLwiFgQEQuWLVu2rsuUJI2x3oVnRGwLHAjsBuwEbBERLx8cLzNPyMz5mTl/YmJiXZcpSRpjvQtP4NnANZm5LDN/B5wBPHXENUmSeqSP4fkr4MkRsXlEBLAPsGjENUmSeqR34ZmZFwGnAxcDP6G08YSRFiVJ6pU5oy5gbcjM9wDvGXUdkqR+6t2ZpyRJa5vhKUlSI8NTkqRGhqckSY0MT0mSGhmekiQ1MjwlSWpkeEqS1MjwlCSpkeEpSVIjw1OSpEaGpyRJjQxPSZIaGZ6SJDUyPCVJamR4SpLUyPCUJKmR4SlJUiPDU5KkRoanJEmNDE9JkhoZnpIkNTI8JUlqZHhKktTI8JQkqVEvwzMitomI0yPiyohYFBFPGXVNkqT+mDPqAtaSjwP/lpkHRcTGwOajLkiS1B+9C8+I2Bp4BnAYQGb+FvjtKGuSJPVLHy/b7gYsA/4lIn4UEZ+JiC0GR4qIwyNiQUQsWLZs2bqvUpI0tvoYnnOAxwOfzMzHAb8GjhocKTNPyMz5mTl/YmJiXdcoSRpjfQzP64DrMvOi+vx0SphKkjQreheemXkjsDgidq8v7QNcMcKSJEk907sbhqo3ASfXO22vBl414nokST3Sy/DMzEuA+aOuQ5LUT727bCtJ0tpmeEqS1MjwlCSpkeEpSVIjw1OSpEaGpyRJjQxPSZIaGZ6SJDUyPCVJamR4SpLUyPCUJKmR4SlJUqNefjG8NNvmHXX2qEtYp+5v7ZVaeeYpSVIjw1OSpEaGpyRJjQxPSZIaGZ6SJDUyPCVJamR4SpLUyPCUJKmR4SlJUiPDU5KkRoanJEmNDE9JkhoZnpIkNepteEbEhhHxo4j4+qhrkST1S2/DEzgCWDTqIiRJ/dPL8IyIXYADgM+MuhZJUv/0MjyBjwHvAO4ZNkJEHB4RCyJiwbJly9ZZYZKk8de78IyI5wNLM3PhdONl5gmZOT8z509MTKyj6iRJfdC78ASeBvxZRFwLnAo8KyK+ONqSJEl90rvwzMx3ZeYumTkPOBj4dma+fMRlSZJ6pHfhKUnS2jZn1AWsTZl5LnDuiMuQJPWMZ56SJDUyPCVJamR4SpLUyPCUJKmR4SlJUiPDU5KkRoanJEmNDE9JkhoZnpIkNTI8JUlqZHhKktSo199tK0kzNe+os0ddwjp37XEHjLqEseWZpyRJjQxPSZIaGZ6SJDUyPCVJamR4SpLUyPCUJKmR4SlJUiPDU5KkRoanJEmNDE9JkhoZnpIkNTI8JUlqZHhKktSod+EZEQ+OiO9ExBURcXlEHDHqmiRJ/dLHf0l2N/C2zLw4IrYCFkbEOZl5xagLkyT1Q+/OPDNzSWZeXB/fASwCdh5tVZKkPuldeHZFxDzgccBFUww7PCIWRMSCZcuWrfPaJEnjq7fhGRFbAl8BjszM2weHZ+YJmTk/M+dPTEys+wIlSWOrl+EZERtRgvPkzDxj1PVIkvqld+EZEQF8FliUmR8ZdT2SpP7pXXgCTwNeATwrIi6pP/uPuihJUn/07k9VMvN7QIy6DklSf/XxzFOSpLXK8JQkqZHhKUlSI8NTkqRGhqckSY0MT0mSGhmekiQ1MjwlSWpkeEqS1MjwlCSpkeEpSVIjw1OSpEaGpyRJjQxPSZIaGZ6SJDUyPCVJamR4SpLUyPCUJKmR4SlJUiPDU5KkRoanJEmNDE9JkhoZnpIkNTI8JUlqZHhKktTI8JQkqVEvwzMi9o2In0bEzyPiqFHXI0nql96FZ0RsCPwzsB+wB3BIROwx2qokSX3Su/AEngT8PDOvzszfAqcCB464JklSj8wZdQFrwc7A4s7z64C9BkeKiMOBw+vTFRHx087g7YGb11qFo9PXdkF/22a7xs/YtC0+2DT6YLt2ndVixkwfw3NGMvME4ISphkXEgsycv45LWuv62i7ob9ts1/jpa9v62q7V1cfLttcDD+4836W+JknSrOhjeP4QeHhE7BYRGwMHA2eNuCZJUo/07rJtZt4dEW8EvgFsCHwuMy9vnMyUl3N7oK/tgv62zXaNn762ra/tWi2RmaOuQZKksdLHy7aSJK1VhqckSY0Mz44+f61fRFwbET+JiEsiYsGo61ldEfG5iFgaEZd1XtsuIs6JiKvq721HWePqGtK2YyLi+rreLomI/UdZ4+qIiAdHxHci4oqIuDwijqivj/V6m6ZdY73OImLTiPhBRPy4tuu99fXdIuKi2j9+ud6Qeb/lZ55V/Vq/nwHPoXyxwg+BQzLzipEWNksi4lpgfmaOxR9vDxMRzwBWAJ/PzEfX1/4RuDUzj6sHPdtm5jtHWefqGNK2Y4AVmfmhUda2JiJiR2DHzLw4IrYCFgIvBA5jjNfbNO16KWO8ziIigC0yc0VEbAR8DzgCeCtwRmaeGhHHAz/OzE+OstZR8szzPn6t3xjIzPOBWwdePhA4qT4+idKBjZ0hbRt7mbkkMy+uj+8AFlG+CWys19s07RprWayoTzeqPwk8Czi9vj5262u2GZ73mepr/cZ+R+hI4JsRsbB+NWGf7JCZS+rjG4EdRlnMWvDGiLi0XtYdq0ubgyJiHvA44CJ6tN4G2gVjvs4iYsOIuARYCpwD/AJYnpl311H61j82MzzvP56emY+n/LeZv6mXCHsny+cQffos4pPAQ4HHAkuAD4+0mjUQEVsCXwGOzMzbu8PGeb1N0a6xX2eZ+fvMfCzlG9qeBDxytBWtfwzP+/T6a/0y8/r6eylwJmWH6Iub6udPk59DLR1xPbMmM2+qHdk9wKcZ0/VWPzv7CnByZp5RXx779TZVu/qyzgAycznwHeApwDYRMfnFOr3qH1eH4Xmf3n6tX0RsUW9oICK2AJ4LXDb9u8bKWcCh9fGhwNdGWMusmgyX6kWM4XqrN6B8FliUmR/pDBrr9TasXeO+ziJiIiK2qY83o9xEuYgSogfV0cZufc0277btqLeUf4z7vtbv/aOtaHZExEMoZ5tQvpLxS+Patog4Bdib8u+RbgLeA3wVOA2YC/wSeGlmjt2NN0Patjfl8l8C1wKv63xOOBYi4unAd4GfAPfUl4+mfD44tuttmnYdwhivs4h4DOWGoA0pJ1inZeb7aj9yKrAd8CPg5Zn5m9FVOlqGpyRJjbxsK0lSI8NTkqRGhqckSY0MT0mSGhmekiQ1MjwlSWpkeEqS1Oi/AbelH+iUNfv/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_hist(X):\n",
    "    len_ = [len(_) for _ in X]\n",
    "    plt.hist(len_)\n",
    "    plt.title('Histogram of the number of sentences that have a given number of words')\n",
    "    plt.show()\n",
    "    \n",
    "plot_hist(X_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4403520a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:23:59.146139Z",
     "start_time": "2022-01-07T09:23:59.126110Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train_pad = pad_sequences(X_train_token, dtype='float32', padding='post', maxlen=20)\n",
    "X_test_pad = pad_sequences(X_test_token, dtype='float32', padding='post', maxlen=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1048814e",
   "metadata": {},
   "source": [
    "# RNN - embedding trained on corpus\n",
    "\n",
    "Let's now feed this data to a Recurrent Neural Network.\n",
    "\n",
    "model:\n",
    "- an embedding layer whose `input_dim` is the size of your vocabulary (= your `vocab_size`), and whose `output_dim` is the size of the embedding space you want to have\n",
    "- a RNN (SimpleRNN, LSTM, GRU) layer\n",
    "- a Dense layer\n",
    "- an output layer\n",
    "\n",
    "‚ö†Ô∏è **Warning** ‚ö†Ô∏è Here, you don't need a masking layer. Why? Because `layers.Embedding` has a argument to do that directly, which you have to set with `mask_zero=True`. That also means that your data **HAVE TO** be padded with **0** (which is the default behavior). See the [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding#example_2) to understand how it **impacts** the `input_dim`.\n",
    "\n",
    "!`input_dim` should equal size of vocabulary + 1\n",
    "\n",
    "\n",
    "Compile it with the appropriate arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9ff38339",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:24:01.413091Z",
     "start_time": "2022-01-07T09:23:59.910302Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_dimension = 50\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(input_dim=vocab_size + 1, output_dim=embedding_dimension, mask_zero=True))\n",
    "model.add(layers.LSTM(20))\n",
    "model.add(layers.Dense(10, activation=\"relu\"))\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9c763cae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:24:01.422017Z",
     "start_time": "2022-01-07T09:24:01.415364Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, None, 50)          36900     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 20)                5680      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                210       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,801\n",
      "Trainable params: 42,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a49d6f80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:24:08.599346Z",
     "start_time": "2022-01-07T09:24:01.423508Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.6907 - accuracy: 0.7321 - val_loss: 0.6963 - val_accuracy: 0.4167\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.6828 - accuracy: 0.6964 - val_loss: 0.6984 - val_accuracy: 0.4167\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.6735 - accuracy: 0.6964 - val_loss: 0.7011 - val_accuracy: 0.4167\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.6606 - accuracy: 0.6964 - val_loss: 0.7064 - val_accuracy: 0.4167\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.6408 - accuracy: 0.6964 - val_loss: 0.7139 - val_accuracy: 0.4167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbca86ae4f0>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(f'Expected number of parameters : {(vocab_size + 1) * embedding_dimension}')\n",
    "es = EarlyStopping(patience=4, restore_best_weights=True)\n",
    "\n",
    "model.fit(X_train_pad, y_train, \n",
    "          epochs=20, \n",
    "          batch_size=16,\n",
    "          validation_split=0.3,\n",
    "          callbacks=[es]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4576a3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.evaluate(X_test_pad, y_test, verbose=0)\n",
    "\n",
    "print(f'The accuracy evaluated on the test set is of {res[1]*100:.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e7b515",
   "metadata": {},
   "source": [
    "# NN Emebdding with Word2Vec - understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "49205cf8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:24:08.624606Z",
     "start_time": "2022-01-07T09:24:08.600714Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['abusive',\n",
       "  'relationship',\n",
       "  'definitely',\n",
       "  'abuse',\n",
       "  'consensual',\n",
       "  'man',\n",
       "  'beats',\n",
       "  'girlfriend',\n",
       "  'wife',\n",
       "  'bloody',\n",
       "  'ask'],\n",
       " [\"can't\",\n",
       "  'imagine',\n",
       "  'trend',\n",
       "  'isolated',\n",
       "  'wall',\n",
       "  'street',\n",
       "  'seen',\n",
       "  'mother',\n",
       "  'hit',\n",
       "  'glass',\n",
       "  'ceiling',\n",
       "  'many',\n",
       "  'times',\n",
       "  'unintended',\n",
       "  'consequences',\n",
       "  'troubling',\n",
       "  'say',\n",
       "  'least',\n",
       "  'thankfully',\n",
       "  'increased‚Ä¶'],\n",
       " ['maybe',\n",
       "  'people',\n",
       "  'finally',\n",
       "  'listen',\n",
       "  'us',\n",
       "  'baptist',\n",
       "  'ministers',\n",
       "  'deacons',\n",
       "  'others',\n",
       "  'found',\n",
       "  'guilty',\n",
       "  'sex',\n",
       "  'abuse',\n",
       "  'report',\n",
       "  'says'],\n",
       " ['farhan‚Äôs', 'first', 'five', 'minutes', 'gold'],\n",
       " ['ready',\n",
       "  'pounce',\n",
       "  'p',\n",
       "  'ssy',\n",
       "  'acosta',\n",
       "  'man',\n",
       "  'handling',\n",
       "  'white',\n",
       "  'house',\n",
       "  'aid',\n",
       "  'protecting',\n",
       "  'assault',\n",
       "  'thought',\n",
       "  \"that's\",\n",
       "  'p',\n",
       "  'ssy',\n",
       "  'hat',\n",
       "  'wearing',\n",
       "  'tutu',\n",
       "  'twirling',\n",
       "  'cry',\n",
       "  'babies',\n",
       "  'movement',\n",
       "  'scream',\n",
       "  'want'],\n",
       " ['üì∫', 'unsure', \"she'll\", 'watch', 'new'],\n",
       " ['nothing',\n",
       "  'since',\n",
       "  'hate',\n",
       "  'back',\n",
       "  'trying',\n",
       "  'use',\n",
       "  'personal',\n",
       "  'weapon',\n",
       "  'yes',\n",
       "  'get',\n",
       "  'care',\n",
       "  'rape',\n",
       "  'women',\n",
       "  'country',\n",
       "  'legal',\n",
       "  'nonsense',\n",
       "  'egypt',\n",
       "  'outrage'],\n",
       " ['movement', 'change', 'anything', 'bollywood', 'read'],\n",
       " ['shattered',\n",
       "  'cards',\n",
       "  'sure',\n",
       "  'rn',\n",
       "  'every',\n",
       "  'man',\n",
       "  'industry',\n",
       "  'wud',\n",
       "  'trying',\n",
       "  'recollect',\n",
       "  'moments',\n",
       "  'hidden',\n",
       "  'warmth',\n",
       "  \"'gentleman'\",\n",
       "  'behavior',\n",
       "  'fingers',\n",
       "  'crossed'],\n",
       " ['raped',\n",
       "  'almost',\n",
       "  \"i'm\",\n",
       "  'talked',\n",
       "  'first',\n",
       "  'time',\n",
       "  'couple',\n",
       "  'years',\n",
       "  'ago',\n",
       "  'yet',\n",
       "  'share',\n",
       "  'details'],\n",
       " ['need',\n",
       "  'basic',\n",
       "  'common',\n",
       "  'sense',\n",
       "  'look',\n",
       "  'mirror',\n",
       "  'asking',\n",
       "  'questions',\n",
       "  'dump',\n",
       "  'attitude',\n",
       "  'start',\n",
       "  'called',\n",
       "  'among',\n",
       "  'thousands',\n",
       "  'men',\n",
       "  'get',\n",
       "  'proper',\n",
       "  'self',\n",
       "  'think',\n",
       "  'done',\n",
       "  'try',\n",
       "  'trolling'],\n",
       " ['apparently',\n",
       "  'ur',\n",
       "  'echo',\n",
       "  'chamber',\n",
       "  'thick',\n",
       "  'u',\n",
       "  \"can't\",\n",
       "  'see',\n",
       "  'every',\n",
       "  '2nd',\n",
       "  'comment',\n",
       "  'indeed',\n",
       "  'want',\n",
       "  'back',\n",
       "  'look',\n",
       "  'youtube',\n",
       "  'well',\n",
       "  'pepl',\n",
       "  'tired',\n",
       "  'pepl',\n",
       "  'ü§î',\n",
       "  'like',\n",
       "  'u',\n",
       "  'tired',\n",
       "  'played',\n",
       "  'joke',\n",
       "  'crash',\n",
       "  'amp',\n",
       "  'üî•üî•'],\n",
       " ['former',\n",
       "  'state',\n",
       "  'rep',\n",
       "  'sues',\n",
       "  'arizona',\n",
       "  'denying',\n",
       "  \"'due\",\n",
       "  \"process'\",\n",
       "  'expulsion',\n",
       "  'legislature',\n",
       "  'booted',\n",
       "  'year',\n",
       "  'ago',\n",
       "  'accusations',\n",
       "  'sexually',\n",
       "  'harassed',\n",
       "  'women'],\n",
       " ['semi', 'truth', 'dangerous', 'destructive', 'lie'],\n",
       " ['pressing', 'problem', 'violence', 'men', 'address', 'new', 'matilda'],\n",
       " ['power',\n",
       "  'dynamics',\n",
       "  'partner',\n",
       "  'rape',\n",
       "  'abuse',\n",
       "  'almost',\n",
       "  'never',\n",
       "  'gets',\n",
       "  'recorded'],\n",
       " ['fair',\n",
       "  'enough',\n",
       "  'rate',\n",
       "  'false',\n",
       "  'accusations',\n",
       "  'low',\n",
       "  'doesnt',\n",
       "  'discredit',\n",
       "  'point',\n",
       "  'proven',\n",
       "  'false',\n",
       "  'penalty',\n",
       "  'intense',\n",
       "  'proven',\n",
       "  'liar',\n",
       "  'choses',\n",
       "  'lie',\n",
       "  'matter',\n",
       "  'though',\n",
       "  'scarce',\n",
       "  'affects',\n",
       "  'progress',\n",
       "  'era'],\n",
       " ['really',\n",
       "  'heartbreaking',\n",
       "  'someone',\n",
       "  'horrible',\n",
       "  'sad',\n",
       "  'many',\n",
       "  'women',\n",
       "  'go',\n",
       "  'proud',\n",
       "  'everyone',\n",
       "  'come',\n",
       "  'open',\n",
       "  'india',\n",
       "  'women',\n",
       "  'tolerate',\n",
       "  'nuisance'],\n",
       " ['govt',\n",
       "  'led',\n",
       "  'modi',\n",
       "  'used',\n",
       "  'entire',\n",
       "  'state',\n",
       "  'machinery',\n",
       "  'snoop',\n",
       "  'woman',\n",
       "  'interest',\n",
       "  'much',\n",
       "  'us',\n",
       "  'expect',\n",
       "  'sack',\n",
       "  'let',\n",
       "  'go',\n",
       "  'minister',\n",
       "  'mj',\n",
       "  'akbar',\n",
       "  'accused',\n",
       "  'sexual',\n",
       "  'harassment',\n",
       "  'women',\n",
       "  'told',\n",
       "  'since',\n",
       "  'day',\n",
       "  'one',\n",
       "  'sham'],\n",
       " ['tawana',\n",
       "  'burke',\n",
       "  'sp',\n",
       "  'schools',\n",
       "  'real',\n",
       "  'movement',\n",
       "  'started',\n",
       "  'milano',\n",
       "  'hijacked',\n",
       "  'make',\n",
       "  'buck',\n",
       "  'however',\n",
       "  'nobody',\n",
       "  'bothered',\n",
       "  'pointing',\n",
       "  'milano',\n",
       "  'spent',\n",
       "  'two',\n",
       "  'weeks',\n",
       "  'smearing',\n",
       "  'innocent',\n",
       "  'man'],\n",
       " ['l',\n",
       "  'hugger',\n",
       "  'give',\n",
       "  'compliments',\n",
       "  'trying',\n",
       "  'change',\n",
       "  'behaviour',\n",
       "  'due',\n",
       "  'movement',\n",
       "  'one',\n",
       "  'world',\n",
       "  'govt',\n",
       "  'agenda',\n",
       "  'divide',\n",
       "  'conquer'],\n",
       " ['people', 'stupid'],\n",
       " ['must', 'read', 'op', 'ed', 'movement', \"'s\"],\n",
       " ['wait',\n",
       "  'thing',\n",
       "  '‚Äúformally‚Äù',\n",
       "  'join',\n",
       "  'work',\n",
       "  'where‚Äôs',\n",
       "  'application',\n",
       "  'long',\n",
       "  'take',\n",
       "  'reviews',\n",
       "  'vets',\n",
       "  'versus',\n",
       "  'informal',\n",
       "  'people'],\n",
       " ['ted',\n",
       "  'liu',\n",
       "  'beyond',\n",
       "  'gt',\n",
       "  'murder',\n",
       "  'omg',\n",
       "  'another',\n",
       "  'demented',\n",
       "  'dem',\n",
       "  'joins',\n",
       "  'morning',\n",
       "  'joe',\n",
       "  'pervy',\n",
       "  'murder',\n",
       "  'inc',\n",
       "  'club',\n",
       "  'omg'],\n",
       " ['‚Äúthanks',\n",
       "  'movement',\n",
       "  'press',\n",
       "  'forward',\n",
       "  'equipped',\n",
       "  'tools',\n",
       "  'know',\n",
       "  'happens',\n",
       "  'tackle',\n",
       "  '‚Äù',\n",
       "  'camerota',\n",
       "  'said'],\n",
       " ['getting', 'pass', 'democrat', 'men'],\n",
       " ['stopped',\n",
       "  'watching',\n",
       "  'grammy',\n",
       "  'garbage',\n",
       "  'long',\n",
       "  'ago',\n",
       "  'day',\n",
       "  'half',\n",
       "  'naked',\n",
       "  'women',\n",
       "  'exploited',\n",
       "  'everyone',\n",
       "  'claps',\n",
       "  'thinks',\n",
       "  'great',\n",
       "  'one',\n",
       "  'breath',\n",
       "  'cry',\n",
       "  'next',\n",
       "  'reeks',\n",
       "  'hypocrisy'],\n",
       " ['means',\n",
       "  'feminist',\n",
       "  'supporter',\n",
       "  'movement',\n",
       "  'worst',\n",
       "  '‚Äúi',\n",
       "  'feminist',\n",
       "  'but‚Äù',\n",
       "  'statement',\n",
       "  'i‚Äôve',\n",
       "  'seen',\n",
       "  'long',\n",
       "  'time',\n",
       "  'much',\n",
       "  'i‚Äôve',\n",
       "  'screenshotted',\n",
       "  'use',\n",
       "  'example',\n",
       "  'feminist',\n",
       "  'doesn‚Äôt',\n",
       "  'say',\n",
       "  'she‚Äôs',\n",
       "  'feminist'],\n",
       " ['rahul',\n",
       "  'playing',\n",
       "  'cousin',\n",
       "  'sister',\n",
       "  'kejriwal',\n",
       "  'someone',\n",
       "  'going',\n",
       "  'tweek',\n",
       "  'tail',\n",
       "  'also',\n",
       "  'say'],\n",
       " ['mj',\n",
       "  'akbar',\n",
       "  'write',\n",
       "  'book',\n",
       "  'predator',\n",
       "  'publisher',\n",
       "  'modi',\n",
       "  'amp',\n",
       "  'co'],\n",
       " ['control',\n",
       "  'gone',\n",
       "  'equality',\n",
       "  'opportunity',\n",
       "  'men',\n",
       "  'women',\n",
       "  'good',\n",
       "  'equity',\n",
       "  'women',\n",
       "  'bad',\n",
       "  'feeding',\n",
       "  'alt',\n",
       "  'right',\n",
       "  'conservatives',\n",
       "  \"they're\",\n",
       "  'winning',\n",
       "  'please',\n",
       "  'stop',\n",
       "  'left',\n",
       "  'collapses',\n",
       "  'completely'],\n",
       " ['minister',\n",
       "  'state',\n",
       "  'mos',\n",
       "  'external',\n",
       "  'affairs',\n",
       "  'j',\n",
       "  'akbar',\n",
       "  'monday',\n",
       "  'filed',\n",
       "  'defamation',\n",
       "  'case',\n",
       "  \"delhi's\",\n",
       "  'patiala',\n",
       "  'house',\n",
       "  'court',\n",
       "  'priya',\n",
       "  'ramani',\n",
       "  'journalist',\n",
       "  'alleged',\n",
       "  'akbar',\n",
       "  'sexually',\n",
       "  'harassed'],\n",
       " ['list', 'shame', 'amp', 'shameless'],\n",
       " ['give',\n",
       "  \"'em\",\n",
       "  'time',\n",
       "  'gather',\n",
       "  'know',\n",
       "  'wish',\n",
       "  'ill',\n",
       "  \"everything's\",\n",
       "  \"that's\",\n",
       "  'wrong',\n",
       "  'world',\n",
       "  'please',\n",
       "  'go',\n",
       "  'way',\n",
       "  'see',\n",
       "  'even',\n",
       "  'want',\n",
       "  'personally',\n",
       "  'know',\n",
       "  'anyone',\n",
       "  'works'],\n",
       " ['annnnnd', 'like', 'gets', 'ed'],\n",
       " ['family',\n",
       "  'personal',\n",
       "  'exploiting',\n",
       "  'someone',\n",
       "  'sexually',\n",
       "  'work',\n",
       "  'place',\n",
       "  'stop',\n",
       "  'ranting',\n",
       "  'times'],\n",
       " ['miss', 'universe', 'blockchain', 'good', 'times'],\n",
       " ['hits', 'bollywood'],\n",
       " ['midst',\n",
       "  'movement',\n",
       "  'advance',\n",
       "  'women',\n",
       "  'face',\n",
       "  'misogyny',\n",
       "  \"i'm\",\n",
       "  'looking',\n",
       "  'comment',\n",
       "  'piece',\n",
       "  'dm'],\n",
       " ['shameful',\n",
       "  'media',\n",
       "  'fails',\n",
       "  'cover',\n",
       "  'grassroots',\n",
       "  'level',\n",
       "  'stories',\n",
       "  'u',\n",
       "  \"can't\",\n",
       "  'dismiss',\n",
       "  'u',\n",
       "  'friends',\n",
       "  'industry',\n",
       "  'think',\n",
       "  'writing',\n",
       "  'punishment',\n",
       "  'false',\n",
       "  'accusers',\n",
       "  'good',\n",
       "  'moment',\n",
       "  'friend',\n",
       "  'innocent',\n",
       "  'let',\n",
       "  'prove'],\n",
       " ['griffin',\n",
       "  'loved',\n",
       "  'many',\n",
       "  'chris',\n",
       "  'van',\n",
       "  'etten',\n",
       "  'shown',\n",
       "  'fans',\n",
       "  'give',\n",
       "  'damn',\n",
       "  'character',\n",
       "  'amp',\n",
       "  'fans',\n",
       "  'think',\n",
       "  'ever',\n",
       "  'since',\n",
       "  'took',\n",
       "  'writing',\n",
       "  'griffin',\n",
       "  'abominable',\n",
       "  \"he's\",\n",
       "  'isolated',\n",
       "  'jeromes',\n",
       "  'looked',\n",
       "  'worse',\n",
       "  'bensch',\n",
       "  'story'],\n",
       " ['another', 'straved', 'man'],\n",
       " ['please', 'sign', 'support', 'share'],\n",
       " ['man',\n",
       "  \"who's\",\n",
       "  'wronged',\n",
       "  'woman',\n",
       "  'reminded',\n",
       "  'female',\n",
       "  'relations',\n",
       "  'everyday',\n",
       "  'life',\n",
       "  'society',\n",
       "  'wanting',\n",
       "  'amp',\n",
       "  'waiting',\n",
       "  'proof',\n",
       "  'women',\n",
       "  'girls',\n",
       "  'lose',\n",
       "  'lifetime',\n",
       "  'life',\n",
       "  'need',\n",
       "  'proof',\n",
       "  'talk',\n",
       "  'men',\n",
       "  'wronged',\n",
       "  'us'],\n",
       " ['movement',\n",
       "  'soni',\n",
       "  'razdan',\n",
       "  'opens',\n",
       "  'time',\n",
       "  '‚Äúsomebody',\n",
       "  'tried',\n",
       "  'rape‚Äù'],\n",
       " ['bombing', 'suspect', 'pro', 'trump', 'bumper', 'stickers', 'van'],\n",
       " ['calling',\n",
       "  'domestic',\n",
       "  'violence',\n",
       "  'would',\n",
       "  'mean',\n",
       "  'women',\n",
       "  'would',\n",
       "  'calling',\n",
       "  'husbands',\n",
       "  'it‚Äôs',\n",
       "  'easier',\n",
       "  'call',\n",
       "  'someone',\n",
       "  'assaulted',\n",
       "  'past',\n",
       "  'gotten',\n",
       "  'much',\n",
       "  'traction'],\n",
       " [\"that's\",\n",
       "  'fairly',\n",
       "  'large',\n",
       "  'bail',\n",
       "  'must',\n",
       "  'pretty',\n",
       "  'serious',\n",
       "  \"it'll\",\n",
       "  'interesting',\n",
       "  'see',\n",
       "  'woman',\n",
       "  'filed',\n",
       "  'charges',\n",
       "  'treated'],\n",
       " ['heels'],\n",
       " ['‚≠êÔ∏è',\n",
       "  'days',\n",
       "  'left',\n",
       "  'donate',\n",
       "  '‚≠êÔ∏è',\n",
       "  'every',\n",
       "  'purchase',\n",
       "  'donation',\n",
       "  'planned',\n",
       "  'parenthood',\n",
       "  'pussy',\n",
       "  'hats',\n",
       "  'sale',\n",
       "  'amp',\n",
       "  'free',\n",
       "  'shipping',\n",
       "  'us'],\n",
       " ['pooja', \"bhatt's\", 'sensible', 'opinion'],\n",
       " ['god', 'bless', 'i‚Äôll', 'pray', 'amp', 'real', 'women'],\n",
       " ['ask', 'father', 'allegations'],\n",
       " ['erm', 'yes', 'please'],\n",
       " ['stop',\n",
       "  'looking',\n",
       "  'approval',\n",
       "  'people',\n",
       "  'never',\n",
       "  'understand',\n",
       "  'weight',\n",
       "  'assignment'],\n",
       " ['there‚Äôs',\n",
       "  'quiet',\n",
       "  'movement',\n",
       "  'unfolding',\n",
       "  'government‚Äôs',\n",
       "  'comments',\n",
       "  'section',\n",
       "  '‚Äì',\n",
       "  'mother',\n",
       "  'jones'],\n",
       " ['mom', 'said', 'dad'],\n",
       " ['biggest',\n",
       "  'lier',\n",
       "  'blocked',\n",
       "  'asking',\n",
       "  'question',\n",
       "  'singerkarthik',\n",
       "  'issue',\n",
       "  'mental',\n",
       "  'think',\n",
       "  'attention',\n",
       "  'seeker',\n",
       "  'plz',\n",
       "  'suspend',\n",
       "  'account',\n",
       "  'misusing',\n",
       "  'plz',\n",
       "  'suspend',\n",
       "  'dz',\n",
       "  'account'],\n",
       " ['genuine', 'moment', 'ü§£ü§£ü§£ü§£ü§£ü§£'],\n",
       " ['ex', 'wife', 'victim', 'reports', 'surfacing', 'stormy', 'daniels'],\n",
       " ['love', 'giving', 'subway', 'seat', 'don‚Äôt', 'want'],\n",
       " ['makes',\n",
       "  'migrant',\n",
       "  'workers',\n",
       "  'indigenous',\n",
       "  'people',\n",
       "  'especially',\n",
       "  'vulnerable',\n",
       "  'forced',\n",
       "  'labor',\n",
       "  'worldwide'],\n",
       " ['apologetic', 'feminist'],\n",
       " ['man',\n",
       "  \"'cannot\",\n",
       "  \"woman'\",\n",
       "  'polygamy',\n",
       "  'canadian',\n",
       "  'muslim',\n",
       "  'community',\n",
       "  'could',\n",
       "  'another',\n",
       "  'moment',\n",
       "  'cbc',\n",
       "  'news'],\n",
       " ['might',\n",
       "  'mueller',\n",
       "  'might',\n",
       "  'stormy‚Äôs',\n",
       "  'emerging',\n",
       "  'might',\n",
       "  'deutsche',\n",
       "  'bank',\n",
       "  'might',\n",
       "  'dems',\n",
       "  'starting',\n",
       "  'serious',\n",
       "  'oversight',\n",
       "  'house'],\n",
       " ['shows',\n",
       "  'trp',\n",
       "  'hungry',\n",
       "  'media',\n",
       "  'must',\n",
       "  'nt',\n",
       "  'misuse',\n",
       "  'else',\n",
       "  'gain',\n",
       "  'know',\n",
       "  'memory',\n",
       "  'indian',\n",
       "  'poor',\n",
       "  'use',\n",
       "  'wisely',\n",
       "  'thanks'],\n",
       " ['louis',\n",
       "  'ck',\n",
       "  'digusting',\n",
       "  'homophobe',\n",
       "  'transphobic',\n",
       "  'bigoted',\n",
       "  'racist',\n",
       "  'white',\n",
       "  'supreamist',\n",
       "  'it‚Äôs',\n",
       "  'trumps',\n",
       "  'america',\n",
       "  'smh',\n",
       "  'ü§¶üèª\\u200d‚ôÄÔ∏è',\n",
       "  'üò¢'],\n",
       " ['dear', \"can't\", 'say', 'care', 'vote', 'confirm', 'full', 'shit'],\n",
       " ['moved',\n",
       "  'track',\n",
       "  'last',\n",
       "  'escaped',\n",
       "  'pulling',\n",
       "  'artist',\n",
       "  'don‚Äôt',\n",
       "  'worry',\n",
       "  'next',\n",
       "  'year',\n",
       "  'shriya',\n",
       "  'goshal',\n",
       "  'start',\n",
       "  'tweet',\n",
       "  'agains',\n",
       "  'rajni',\n",
       "  'kamal',\n",
       "  'ar',\n",
       "  'rahman',\n",
       "  'ü§£ü§£ü§£'],\n",
       " ['rape',\n",
       "  'culture',\n",
       "  'doesn‚Äôt',\n",
       "  'exist',\n",
       "  'movement',\n",
       "  'topical',\n",
       "  'historical',\n",
       "  'women',\n",
       "  'men',\n",
       "  'overwhelming',\n",
       "  'perpetrator',\n",
       "  'rape',\n",
       "  'crimes'],\n",
       " ['hey',\n",
       "  'see',\n",
       "  'article',\n",
       "  'i‚Äôm',\n",
       "  'wondering',\n",
       "  'still',\n",
       "  'want',\n",
       "  'advertising',\n",
       "  'since',\n",
       "  'main',\n",
       "  'demo',\n",
       "  'young',\n",
       "  'women'],\n",
       " ['new',\n",
       "  'podcast',\n",
       "  'reminds',\n",
       "  'listeners',\n",
       "  'origins',\n",
       "  'explore',\n",
       "  'solidarity',\n",
       "  'syllabus'],\n",
       " ['melania', 'trump', 'women', 'need', 'heard', '‚Äòshow', 'evidence‚Äô'],\n",
       " ['sherri',\n",
       "  'made',\n",
       "  'false',\n",
       "  'rape',\n",
       "  'allegations',\n",
       "  'amp',\n",
       "  'gets',\n",
       "  'away',\n",
       "  'amp',\n",
       "  'stupidly',\n",
       "  'u',\n",
       "  'take',\n",
       "  'back',\n",
       "  'water',\n",
       "  'bridge',\n",
       "  'amp',\n",
       "  'still',\n",
       "  'ü§¨',\n",
       "  'cheating',\n",
       "  'guy',\n",
       "  'met'],\n",
       " ['two',\n",
       "  'girls',\n",
       "  'saw',\n",
       "  'father',\n",
       "  'love',\n",
       "  'look',\n",
       "  'slimed',\n",
       "  'grow',\n",
       "  'carrying',\n",
       "  'experience'],\n",
       " ['senator',\n",
       "  'franken',\n",
       "  'paid',\n",
       "  'high',\n",
       "  'price',\n",
       "  'lived',\n",
       "  'edgy',\n",
       "  'life',\n",
       "  'comedian',\n",
       "  'pre',\n",
       "  'era',\n",
       "  'accused',\n",
       "  'raping',\n",
       "  '13yo',\n",
       "  'child',\n",
       "  'grabbing',\n",
       "  'pussies',\n",
       "  'consistent',\n",
       "  'top',\n",
       "  'misogyny',\n",
       "  'amp',\n",
       "  'denigration',\n",
       "  'women'],\n",
       " ['know',\n",
       "  'dems',\n",
       "  'know',\n",
       "  'also',\n",
       "  'disgraced',\n",
       "  'movement',\n",
       "  'disgraceful',\n",
       "  'use',\n",
       "  'women',\n",
       "  'attempt',\n",
       "  'attain',\n",
       "  'power',\n",
       "  'please',\n",
       "  'take',\n",
       "  'hard',\n",
       "  'look',\n",
       "  'transpired',\n",
       "  'get',\n",
       "  'truth',\n",
       "  'dont',\n",
       "  'let',\n",
       "  'use',\n",
       "  'pain'],\n",
       " ['michael',\n",
       "  'jackson',\n",
       "  'accused',\n",
       "  'kids',\n",
       "  'accused',\n",
       "  'parents',\n",
       "  'urged',\n",
       "  'three',\n",
       "  'tried',\n",
       "  'profit',\n",
       "  'four',\n",
       "  'girls',\n",
       "  'accused',\n",
       "  'man',\n",
       "  'even',\n",
       "  'rich',\n",
       "  'jury',\n",
       "  'found',\n",
       "  'guilty',\n",
       "  'two',\n",
       "  'hours'],\n",
       " ['brought', 'powerful', 'men', 'nearly', 'half', 'replacements', 'women']]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "627d0759",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:33:28.578431Z",
     "start_time": "2022-01-07T09:33:28.535318Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'harassment' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7781/2820316385.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mwv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#wv[\"familiar\"] --> in X_train but not wv??\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'harassment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/project_BAN/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key_or_keys)\u001b[0m\n\u001b[1;32m    393\u001b[0m         \"\"\"\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_KEY_TYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey_or_keys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/project_BAN/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, key, norm)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \"\"\"\n\u001b[0;32m--> 438\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_norms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/project_BAN/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_index\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Key '{key}' not present\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Key 'harassment' not present\""
     ]
    }
   ],
   "source": [
    "word2vec = Word2Vec(sentences=X_train)\n",
    "wv = word2vec.wv\n",
    "#wv[\"familiar\"] --> in X_train but not wv??\n",
    "size = len(wv['harassment'])\n",
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfabe6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:24:08.700429Z",
     "start_time": "2022-01-07T09:24:08.700395Z"
    }
   },
   "outputs": [],
   "source": [
    "wv.most_similar('harassment')\n",
    "#word_embedding = wv[''harassment']\n",
    "#wv.similar_by_vector(word_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ef644e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:24:08.704380Z",
     "start_time": "2022-01-07T09:24:08.704358Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Vocabulary size', len(wv.key_to_index))\n",
    "diff_words = set([_ for elt in X_train for _ in elt])\n",
    "print('Number of different words in the train set', len(diff_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ffdb74",
   "metadata": {},
   "source": [
    "In a nutshell, this internal NN predicts a word from the surroundings words in a sentences. So it chooses many splits in the different sentences, choose some words as inputs  ùëã  and a word as output  ùë¶  which it tries to predict, in the embedding space.\n",
    "\n",
    "And as any neural network, Word2Vec has some hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d61b06",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Word2Vec hyperparameters\n",
    "\n",
    "\n",
    "The first important hyperparameter is the `vector_size` argument. It corresponds to the size of the embedding space. Learn a new `word2vec_2` model, still trained on the `X_train`, but with a smaller or higher `vector_size`.\n",
    "\n",
    "Verify on some words that the corresponding embedding is of your selected size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c48a7b8",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dae46c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:24:08.705497Z",
     "start_time": "2022-01-07T09:24:08.705483Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "word2vec_size30 = Word2Vec(sentences=X_train, vector_size = 30)\n",
    "wv_size30 = word2vec_size30.wv\n",
    "wv_size30.most_similar('harassment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee473f96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:24:08.706391Z",
     "start_time": "2022-01-07T09:24:08.706377Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print('Vocabulary size', len(wv.key_to_index))\n",
    "# diff_words = set([_ for elt in X_train for _ in elt])\n",
    "# print('Number of different words in the train set', len(diff_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40b6555",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:24:08.709010Z",
     "start_time": "2022-01-07T09:24:08.708972Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "word2vec_size50 = Word2Vec(sentences=X_train, vector_size = 50)\n",
    "wv_size50 = word2vec_size50.wv\n",
    "wv_size50.most_similar('harassment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb7a477",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:24:08.711052Z",
     "start_time": "2022-01-07T09:24:08.711036Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "word2vec_size100 = Word2Vec(sentences=X_train, vector_size = 100)\n",
    "wv_size100 = word2vec_size100.wv\n",
    "wv_size100.most_similar('harassment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c281fcbe",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## min_count\n",
    "Second hyperparameter `min_count`,  min # of times a word has to occur in order to be in embedding space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2889445f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:24:08.712108Z",
     "start_time": "2022-01-07T09:24:08.712091Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# min_count:  min # of times a word has to occur in order to nbe in embedding space\n",
    "word2vec3 = Word2Vec(sentences=X_train, vector_size = 30, min_count = 1)\n",
    "wv3 = word2vec.wv\n",
    "wv3.most_similar('harassment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b50e8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:24:08.713979Z",
     "start_time": "2022-01-07T09:24:08.713961Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## wv3[\"familiar\"] -- > syill not in wv, why?\n",
    "print('Vocabulary size', len(wv3.key_to_index))\n",
    "diff_words = set([_ for elt in X_train for _ in elt])\n",
    "print('Number of different words in the train set', len(diff_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa35aa73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:24:08.715854Z",
     "start_time": "2022-01-07T09:24:08.715831Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "word2vec_0 = Word2Vec(sentences=X_train, vector_size=50, min_count=1)\n",
    "word2vec_1 = Word2Vec(sentences=X_train, vector_size=50, min_count=2)\n",
    "word2vec_2 = Word2Vec(sentences=X_train, vector_size=50, min_count=3)\n",
    "word2vec_3 = Word2Vec(sentences=X_train, vector_size=50, min_count=5)\n",
    "word2vec_4 = Word2Vec(sentences=X_train, vector_size=50, min_count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ec180f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:24:08.717095Z",
     "start_time": "2022-01-07T09:24:08.717078Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "word2vec_1.wv[\"harassment\"]\n",
    "len(word2vec_1.wv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9476f6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:24:08.720284Z",
     "start_time": "2022-01-07T09:24:08.720260Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f'Number of word in W2V #1 : {len(word2vec_0.wv.key_to_index)}')\n",
    "print(f'Number of word in W2V #1 : {len(word2vec_1.wv.key_to_index)}')\n",
    "print(f'Number of word in W2V #2 : {len(word2vec_2.wv.key_to_index)}')\n",
    "print(f'Number of word in W2V #3 : {len(word2vec_3.wv.key_to_index)}')\n",
    "print(f'Number of word in W2V #4 : {len(word2vec_4.wv.key_to_index)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ed7c1975",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:24:08.755560Z",
     "start_time": "2022-01-07T09:24:08.748024Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "737"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_words = set([_ for elt in X_train for _ in elt])\n",
    "len(diff_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f9746309",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:24:08.975582Z",
     "start_time": "2022-01-07T09:24:08.958885Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('it‚Äôs', 0.3642662763595581),\n",
       " ('need', 0.27195632457733154),\n",
       " ('like', 0.19107677042484283),\n",
       " ('woman', 0.19076630473136902),\n",
       " ('abuse', 0.1906258761882782),\n",
       " ('news', 0.18562272191047668),\n",
       " ('hear', 0.18191683292388916),\n",
       " ('end', 0.17673398554325104),\n",
       " ('don‚Äôt', 0.1759101301431656),\n",
       " ('nothing', 0.1713448464870453)]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_3.wv.most_similar(\"harassment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cef0111",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## window\n",
    "The arguments you have seen (vector_size, min_count and window) are usually the one that you should start changing to get a better performance for your model.\n",
    "\n",
    "Other hyperparameters in doc (cf 8.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "aa253fd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:24:09.709051Z",
     "start_time": "2022-01-07T09:24:09.660464Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "word2vec_3_window1 = Word2Vec(sentences=X_train, vector_size=50, min_count=3, window = 1)\n",
    "word2vec_3 = Word2Vec(sentences=X_train, vector_size=50, min_count=3, window = 5) # default 5\n",
    "word2vec_3_window8 = Word2Vec(sentences=X_train, vector_size=50, min_count=3, window = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a7c22549",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:24:10.194455Z",
     "start_time": "2022-01-07T09:24:10.190639Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(f'Number of word in W2V #window 1 : {len(word2vec_3_window1 .wv.key_to_index)}')\n",
    "# print(f'Number of word in W2V #window 5: {len(word2vec_3.wv.key_to_index)}')\n",
    "# print(f'Number of word in W2V #window 8 : {len(word2vec_3_window8 .wv.key_to_index)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "dd95faa6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:24:10.545225Z",
     "start_time": "2022-01-07T09:24:10.534596Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#word2vec_3_window1.wv.most_similar(\"harassment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ca9a0359",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:24:10.785288Z",
     "start_time": "2022-01-07T09:24:10.777039Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#word2vec_3.wv.most_similar(\"harassment\") # default 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "81c22358",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:24:11.015726Z",
     "start_time": "2022-01-07T09:24:11.007687Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#word2vec_3_window8.wv.most_similar(\"harassment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554066d3",
   "metadata": {},
   "source": [
    "# Embedding: convert W2V\n",
    "\n",
    "Remember that word2vec is the first step to the overall process of feeding such a representation into a RNN, as shown here :\n",
    "\n",
    "<img src=\"word2vec_representation.png\" width=\"400px\" />\n",
    "\n",
    "\n",
    "\n",
    "Now, let's work on Step 2 by converting the training and test data into their vector representation to be ready to be feed in RNNs.\n",
    "\n",
    "‚ùì **Question** ‚ùì Now, write a function that, given a sentence, returns a matrix that corresponds to the embedding of the full sentence, which means that you have to embed each word one after the other and concatenate the result to output a 2D matrix (be sure that your output is a NumPy array)\n",
    "\n",
    "‚ùó **Remark** ‚ùó You will probably notice that some words you are trying to convert throw errors as they are said not to belong to the dictionary:\n",
    "\n",
    "- for the test set, this is understandable: some words were not in the train set and thus their embedded representation is unknown\n",
    "- for the train set, due to `min_count` hyperparameter, not all the words have a vector representation\n",
    "\n",
    "In any case, just skip the missing words here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac87bc1c",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Embedding function\n",
    "\n",
    "- each word --> vector w2v\n",
    "- each sentence ---> matrix of w2v \n",
    "- e.g sentence of 5 words and embedding size 10 ---> matrix  5x10 --> # of words>=min_count x vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "3c686fb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:25:03.328853Z",
     "start_time": "2022-01-07T09:25:03.321875Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def embed_sentence(word2vec, sentence):\n",
    "    \"\"\" \n",
    "    sentence to matrix\n",
    "    \"\"\"\n",
    "    embedded_sentence = []\n",
    "    for word in sentence:\n",
    "        if word in word2vec.wv:\n",
    "            embedded_sentence.append(word2vec.wv[word])\n",
    "        \n",
    "    return np.array(embedded_sentence)\n",
    "   \n",
    "\n",
    "def embedding(word2vec, sentences):\n",
    "    \"\"\" \n",
    "    list(sentences in words)---> list(matrices)\n",
    "    \"\"\"\n",
    "    embed = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        embedded_sentence = embed_sentence(word2vec, sentence)\n",
    "        embed.append(embedded_sentence)\n",
    "        \n",
    "    return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "58a17ae7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:25:07.178558Z",
     "start_time": "2022-01-07T09:25:07.141693Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 50)\n"
     ]
    }
   ],
   "source": [
    "sentence = X_train[0]\n",
    "word2vec = Word2Vec(sentences = X_train, vector_size=50, min_count = 2, window = 6)\n",
    "\n",
    "print(embed_sentence(word2vec, sentence).shape)\n",
    "#embed_sentence(word2vec, sentence)  ## --> 4 words in 50D --> 4x50 mx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "5111013c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:25:08.002958Z",
     "start_time": "2022-01-07T09:25:07.985541Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "80 80\n",
      "dim of first sentence  (3, 50)\n",
      "dim of 2nd  sentence  (6, 50)\n"
     ]
    }
   ],
   "source": [
    "X_train_embedded = embedding(word2vec, X_train)\n",
    "print(type(X_train))\n",
    "print(len(X_train), len(X_train_embedded))\n",
    "print(f'dim of first sentence  {X_train_embedded[0].shape}')\n",
    "print(f'dim of 2nd  sentence  {X_train_embedded[1].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c21aa2d",
   "metadata": {},
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95b2f68",
   "metadata": {},
   "source": [
    "In order to have ready-to-use data, do not forget to pad them in order to have tensors that can be divided in batch sizes during the optimization. Store the padedd values in X_train_pad and X_test_pad. Do not forget the important arguments of the padding ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32eea7ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:31:54.844203Z",
     "start_time": "2022-01-07T09:31:54.837194Z"
    }
   },
   "source": [
    "#! padding with zeros and in the end ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "bac41978",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:27:36.305285Z",
     "start_time": "2022-01-07T09:27:36.291179Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedd\n",
    "X_train_embedded = embedding(word2vec, X_train)\n",
    "X_test_embedded = embedding(word2vec, X_train)\n",
    "\n",
    "assert(len(X_train_embedded) == len(X_train))\n",
    "len(X_train_embedded) # list of 80 matrices of xxx rows and 50 columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b95ce74e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:30:48.150060Z",
     "start_time": "2022-01-07T09:30:48.128107Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 16, 50)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pad\n",
    "X_train_pad = pad_sequences(X_train_embedded, dtype='float32', padding='post')\n",
    "X_test_pad = pad_sequences(X_test_embedded, dtype='float32', padding='post')\n",
    "\n",
    "assert(len(X_train_pad.shape) == 3)\n",
    "X_train_pad.shape  ## array 80 matrices of 16x50 or 50x16? \n",
    "#!16 lmax length of senetnces in X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aae7333",
   "metadata": {},
   "source": [
    "# Modelling NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d154fa83",
   "metadata": {},
   "source": [
    "## Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "bff9372e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:40:03.591229Z",
     "start_time": "2022-01-07T09:40:03.557713Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>655324</td>\n",
       "      <td>No dif between  movement selectively denying a portion of society presumption of innocence and proper due process than what white mobs did blacks before lynching them, mob to Jap Americans in 1940's, or Nazis to Jews. You all belong to the same clubs...PATHETIC.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>527150</td>\n",
       "      <td>International  March\\nHollywood CA lead by Indigenous People.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>631941</td>\n",
       "      <td>Those last lines of ‚ÄúLady Lazarus‚Äù have a blazing incantatory power. I find they come to mind when a new  scandal breaks.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>245725</td>\n",
       "      <td>will    step up and stop working with  ??\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>596593</td>\n",
       "      <td>, please let   know if   will be  and worlds currency numeraire on 1/1/19.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  \\\n",
       "0  655324   \n",
       "1  527150   \n",
       "2  631941   \n",
       "3  245725   \n",
       "4  596593   \n",
       "\n",
       "                                                                                                                                                                                                                                                                      text  \\\n",
       "0   No dif between  movement selectively denying a portion of society presumption of innocence and proper due process than what white mobs did blacks before lynching them, mob to Jap Americans in 1940's, or Nazis to Jews. You all belong to the same clubs...PATHETIC.   \n",
       "1                                                                                                                                                                                                            International  March\\nHollywood CA lead by Indigenous People.   \n",
       "2                                                                                                                                                Those last lines of ‚ÄúLady Lazarus‚Äù have a blazing incantatory power. I find they come to mind when a new  scandal breaks.   \n",
       "3                                                                                                                                                                                                                           will    step up and stop working with  ??\\n      \n",
       "4                                                                                                                                                                                               , please let   know if   will be  and worlds currency numeraire on 1/1/19.   \n",
       "\n",
       "   category  \n",
       "0         1  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "0fde18c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:40:46.230665Z",
     "start_time": "2022-01-07T09:40:46.221591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    52\n",
       "1    48\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "910104c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:37:05.349364Z",
     "start_time": "2022-01-07T09:37:05.329677Z"
    }
   },
   "outputs": [],
   "source": [
    "# Embed the training and test sentences\n",
    "X_train_embed = embedding(word2vec, X_train)\n",
    "X_test_embed = embedding(word2vec, X_test)\n",
    "\n",
    "\n",
    "# Pad the training and test embedded sentences\n",
    "X_train_pad = pad_sequences(X_train_embed, dtype='float32', padding='post', maxlen=200)\n",
    "X_test_pad = pad_sequences(X_test_embed, dtype='float32', padding='post', maxlen=200)\n",
    "\n",
    "\n",
    "for X in [X_train_pad, X_test_pad]:\n",
    "    assert type(X) == np.ndarray\n",
    "    assert X.shape[-1] == word2vec.wv.vector_size\n",
    "\n",
    "\n",
    "assert X_train_pad.shape[0] == len(X_train)\n",
    "assert X_test_pad.shape[0] == len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaee1b86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f416050",
   "metadata": {},
   "source": [
    "## Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "4445b0fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:44:46.663417Z",
     "start_time": "2022-01-07T09:44:46.655248Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels in train set {0: 39, 1: 41}\n",
      "Baseline accuracy:  {0.5}\n",
      "Acurracy to bit:  {0.9242959631652211}\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "counts = dict(zip(unique, counts))\n",
    "print('Number of labels in train set', counts)\n",
    "print('Baseline accuracy: ', {1/2})\n",
    "print('Acurracy to bit: ', {(4866 + 64190) / 74712})\n",
    "#y_pred = 0 if counts[0] > counts[1] else 1\n",
    "#print('Baseline accuracy: ', accuracy_score(y_test, [y_pred]*len(y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19134b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:45:59.808066Z",
     "start_time": "2022-01-07T09:45:59.804711Z"
    }
   },
   "source": [
    "## Initial RNN model \n",
    "use the NN model, and train with my data?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "e24e5152",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:46:47.438340Z",
     "start_time": "2022-01-07T09:46:47.342777Z"
    }
   },
   "outputs": [],
   "source": [
    "def init_model():\n",
    "    model = Sequential()\n",
    "    model.add(layers.Masking())\n",
    "    model.add(layers.LSTM(20, activation='tanh'))\n",
    "    model.add(layers.Dense(15, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "f1eb9fcf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T10:27:08.870843Z",
     "start_time": "2022-01-07T10:27:08.842649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_2 (Masking)         (None, 200, None)         0         \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 20)                5680      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 15)                315       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 16        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,011\n",
      "Trainable params: 6,011\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "7c4bd5ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:48:04.942247Z",
     "start_time": "2022-01-07T09:47:34.866810Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 4s 903ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6923 - val_accuracy: 0.5417\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.6930 - accuracy: 0.5893 - val_loss: 0.6917 - val_accuracy: 0.5417\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.6925 - accuracy: 0.5536 - val_loss: 0.6909 - val_accuracy: 0.5417\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.6921 - accuracy: 0.5000 - val_loss: 0.6902 - val_accuracy: 0.5417\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 0.6919 - accuracy: 0.5536 - val_loss: 0.6895 - val_accuracy: 0.5417\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.6918 - accuracy: 0.5000 - val_loss: 0.6890 - val_accuracy: 0.6667\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 223ms/step - loss: 0.6912 - accuracy: 0.6429 - val_loss: 0.6883 - val_accuracy: 0.6667\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 1s 332ms/step - loss: 0.6909 - accuracy: 0.6429 - val_loss: 0.6876 - val_accuracy: 0.6667\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 1s 149ms/step - loss: 0.6908 - accuracy: 0.5893 - val_loss: 0.6872 - val_accuracy: 0.6667\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.6903 - accuracy: 0.6429 - val_loss: 0.6864 - val_accuracy: 0.6667\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.6900 - accuracy: 0.6429 - val_loss: 0.6853 - val_accuracy: 0.6667\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.6896 - accuracy: 0.6429 - val_loss: 0.6846 - val_accuracy: 0.6667\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.6892 - accuracy: 0.6429 - val_loss: 0.6833 - val_accuracy: 0.6667\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.6889 - accuracy: 0.6429 - val_loss: 0.6822 - val_accuracy: 0.6667\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.6886 - accuracy: 0.6429 - val_loss: 0.6814 - val_accuracy: 0.6667\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.6883 - accuracy: 0.6429 - val_loss: 0.6800 - val_accuracy: 0.6667\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 340ms/step - loss: 0.6876 - accuracy: 0.6429 - val_loss: 0.6792 - val_accuracy: 0.6667\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 1s 285ms/step - loss: 0.6875 - accuracy: 0.6429 - val_loss: 0.6776 - val_accuracy: 0.6667\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.6869 - accuracy: 0.6429 - val_loss: 0.6767 - val_accuracy: 0.6667\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.6864 - accuracy: 0.6429 - val_loss: 0.6751 - val_accuracy: 0.6667\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.6860 - accuracy: 0.6429 - val_loss: 0.6738 - val_accuracy: 0.6667\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.6855 - accuracy: 0.6429 - val_loss: 0.6719 - val_accuracy: 0.6667\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.6849 - accuracy: 0.6429 - val_loss: 0.6700 - val_accuracy: 0.6667\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.6845 - accuracy: 0.6429 - val_loss: 0.6683 - val_accuracy: 0.6667\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.6847 - accuracy: 0.6429 - val_loss: 0.6673 - val_accuracy: 0.6667\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.6837 - accuracy: 0.6429 - val_loss: 0.6653 - val_accuracy: 0.6667\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.6834 - accuracy: 0.6429 - val_loss: 0.6644 - val_accuracy: 0.6667\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.6827 - accuracy: 0.6429 - val_loss: 0.6623 - val_accuracy: 0.6667\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.6823 - accuracy: 0.6429 - val_loss: 0.6607 - val_accuracy: 0.6667\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 0.6817 - accuracy: 0.6429 - val_loss: 0.6586 - val_accuracy: 0.6667\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.6814 - accuracy: 0.6429 - val_loss: 0.6560 - val_accuracy: 0.6667\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 0.6807 - accuracy: 0.6429 - val_loss: 0.6542 - val_accuracy: 0.6667\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.6809 - accuracy: 0.6429 - val_loss: 0.6527 - val_accuracy: 0.6667\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.6799 - accuracy: 0.6429 - val_loss: 0.6501 - val_accuracy: 0.6667\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.6798 - accuracy: 0.6429 - val_loss: 0.6490 - val_accuracy: 0.6667\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.6791 - accuracy: 0.6429 - val_loss: 0.6469 - val_accuracy: 0.6667\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.6786 - accuracy: 0.6429 - val_loss: 0.6448 - val_accuracy: 0.6667\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.6781 - accuracy: 0.6429 - val_loss: 0.6427 - val_accuracy: 0.6667\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.6783 - accuracy: 0.6429 - val_loss: 0.6401 - val_accuracy: 0.6667\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 256ms/step - loss: 0.6779 - accuracy: 0.6429 - val_loss: 0.6397 - val_accuracy: 0.6667\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 1s 339ms/step - loss: 0.6770 - accuracy: 0.6429 - val_loss: 0.6374 - val_accuracy: 0.6667\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.6770 - accuracy: 0.6429 - val_loss: 0.6370 - val_accuracy: 0.6667\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.6764 - accuracy: 0.6429 - val_loss: 0.6359 - val_accuracy: 0.6667\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.6759 - accuracy: 0.6429 - val_loss: 0.6340 - val_accuracy: 0.6667\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 167ms/step - loss: 0.6757 - accuracy: 0.6429 - val_loss: 0.6332 - val_accuracy: 0.6667\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.6761 - accuracy: 0.6429 - val_loss: 0.6327 - val_accuracy: 0.6667\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.6761 - accuracy: 0.6429 - val_loss: 0.6323 - val_accuracy: 0.6667\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.6748 - accuracy: 0.6429 - val_loss: 0.6307 - val_accuracy: 0.6667\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.6745 - accuracy: 0.6429 - val_loss: 0.6291 - val_accuracy: 0.6667\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 284ms/step - loss: 0.6740 - accuracy: 0.6429 - val_loss: 0.6275 - val_accuracy: 0.6667\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 0.6739 - accuracy: 0.6429 - val_loss: 0.6269 - val_accuracy: 0.6667\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 0.6742 - accuracy: 0.6429 - val_loss: 0.6250 - val_accuracy: 0.6667\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.6731 - accuracy: 0.6429 - val_loss: 0.6237 - val_accuracy: 0.6667\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 167ms/step - loss: 0.6729 - accuracy: 0.6429 - val_loss: 0.6219 - val_accuracy: 0.6667\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.6727 - accuracy: 0.6429 - val_loss: 0.6218 - val_accuracy: 0.6667\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.6730 - accuracy: 0.6429 - val_loss: 0.6202 - val_accuracy: 0.6667\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.6724 - accuracy: 0.6429 - val_loss: 0.6204 - val_accuracy: 0.6667\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.6716 - accuracy: 0.6429 - val_loss: 0.6189 - val_accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.6712 - accuracy: 0.6429 - val_loss: 0.6180 - val_accuracy: 0.6667\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.6711 - accuracy: 0.6429 - val_loss: 0.6172 - val_accuracy: 0.6667\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.6721 - accuracy: 0.6607 - val_loss: 0.6161 - val_accuracy: 0.6667\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.6712 - accuracy: 0.6429 - val_loss: 0.6150 - val_accuracy: 0.6667\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.6703 - accuracy: 0.6429 - val_loss: 0.6145 - val_accuracy: 0.6667\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.6699 - accuracy: 0.6429 - val_loss: 0.6136 - val_accuracy: 0.6667\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 360ms/step - loss: 0.6695 - accuracy: 0.6429 - val_loss: 0.6134 - val_accuracy: 0.6667\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.6695 - accuracy: 0.6429 - val_loss: 0.6135 - val_accuracy: 0.6667\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 226ms/step - loss: 0.6702 - accuracy: 0.6607 - val_loss: 0.6123 - val_accuracy: 0.6667\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.6687 - accuracy: 0.6429 - val_loss: 0.6119 - val_accuracy: 0.6667\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.6686 - accuracy: 0.6429 - val_loss: 0.6108 - val_accuracy: 0.6667\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.6681 - accuracy: 0.6607 - val_loss: 0.6102 - val_accuracy: 0.6667\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.6679 - accuracy: 0.6429 - val_loss: 0.6105 - val_accuracy: 0.6667\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.6676 - accuracy: 0.6607 - val_loss: 0.6106 - val_accuracy: 0.6667\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.6682 - accuracy: 0.6607 - val_loss: 0.6093 - val_accuracy: 0.6667\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.6669 - accuracy: 0.6607 - val_loss: 0.6094 - val_accuracy: 0.6667\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.6665 - accuracy: 0.6607 - val_loss: 0.6083 - val_accuracy: 0.6667\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6665 - accuracy: 0.6607 - val_loss: 0.6086 - val_accuracy: 0.6667\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 0.6658 - accuracy: 0.6607 - val_loss: 0.6080 - val_accuracy: 0.6667\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.6657 - accuracy: 0.6607 - val_loss: 0.6070 - val_accuracy: 0.6667\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.6652 - accuracy: 0.6607 - val_loss: 0.6068 - val_accuracy: 0.6667\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 0.6649 - accuracy: 0.6607 - val_loss: 0.6065 - val_accuracy: 0.6667\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.6656 - accuracy: 0.6786 - val_loss: 0.6054 - val_accuracy: 0.6667\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.6642 - accuracy: 0.6786 - val_loss: 0.6046 - val_accuracy: 0.6667\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.6642 - accuracy: 0.6786 - val_loss: 0.6036 - val_accuracy: 0.6667\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.6635 - accuracy: 0.6607 - val_loss: 0.6040 - val_accuracy: 0.6667\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6630 - accuracy: 0.6786 - val_loss: 0.6039 - val_accuracy: 0.6667\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.6629 - accuracy: 0.7143 - val_loss: 0.6026 - val_accuracy: 0.6667\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.6633 - accuracy: 0.6964 - val_loss: 0.6018 - val_accuracy: 0.7500\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.6630 - accuracy: 0.7321 - val_loss: 0.6008 - val_accuracy: 0.6667\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.6619 - accuracy: 0.6786 - val_loss: 0.6001 - val_accuracy: 0.7500\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.6611 - accuracy: 0.7143 - val_loss: 0.6003 - val_accuracy: 0.7500\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.6630 - accuracy: 0.6964 - val_loss: 0.6009 - val_accuracy: 0.7500\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.6623 - accuracy: 0.7321 - val_loss: 0.5998 - val_accuracy: 0.7500\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 158ms/step - loss: 0.6600 - accuracy: 0.7321 - val_loss: 0.6000 - val_accuracy: 0.7500\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 187ms/step - loss: 0.6601 - accuracy: 0.7321 - val_loss: 0.5991 - val_accuracy: 0.7500\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.6591 - accuracy: 0.7321 - val_loss: 0.5985 - val_accuracy: 0.7500\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 167ms/step - loss: 0.6597 - accuracy: 0.7321 - val_loss: 0.5976 - val_accuracy: 0.7500\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.6584 - accuracy: 0.7321 - val_loss: 0.5973 - val_accuracy: 0.7500\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.6580 - accuracy: 0.7321 - val_loss: 0.5968 - val_accuracy: 0.7500\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.6577 - accuracy: 0.7321 - val_loss: 0.5967 - val_accuracy: 0.7500\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 0.6582 - accuracy: 0.7321 - val_loss: 0.5973 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbca813c9a0>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "model.fit(X_train_pad, y_train, \n",
    "          batch_size = 32,  # low slower?\n",
    "          epochs=100,\n",
    "          validation_split=0.3,\n",
    "          callbacks=[es]\n",
    "         )\n",
    "\n",
    "## accuracy 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "48670d57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:50:29.114832Z",
     "start_time": "2022-01-07T09:50:29.031661Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy evaluated on the test set is of 65.000%\n"
     ]
    }
   ],
   "source": [
    "res = model.evaluate(X_test_pad, y_test, verbose=0)\n",
    "\n",
    "print(f'The accuracy evaluated on the test set is of {res[1]*100:.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac809e6f",
   "metadata": {},
   "source": [
    "## Improve RNN with transfer learning\n",
    "use embedding done on other corpus \n",
    "Use trained NN with others data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "11831377",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T10:02:47.738183Z",
     "start_time": "2022-01-07T10:02:47.713215Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
     ]
    }
   ],
   "source": [
    "## list existing models (trained on >>>> data)\n",
    "print(list(api.info()['models'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "2fcef137",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T10:04:15.549495Z",
     "start_time": "2022-01-07T10:04:03.619569Z"
    }
   },
   "outputs": [],
   "source": [
    "# pick glove-wiki-gigaword-50 for now, will try others--> teachers recommendation?\n",
    "word2vec_transfer = api.load(\"glove-wiki-gigaword-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "4ad3d83e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T10:08:40.429921Z",
     "start_time": "2022-01-07T10:08:40.416158Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n",
      "50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.24895 , -0.47437 , -0.68885 ,  0.36717 , -0.73489 ,  1.0981  ,\n",
       "        1.0047  ,  0.39916 ,  0.010076, -0.5437  , -0.44854 , -0.6424  ,\n",
       "       -0.41055 , -1.6133  ,  0.80873 , -0.63198 , -0.64017 , -0.26496 ,\n",
       "        0.27235 , -0.5545  , -0.19271 ,  0.97283 , -0.18239 ,  0.35686 ,\n",
       "       -0.55335 , -1.6031  ,  0.49933 , -0.38568 ,  0.35579 ,  0.31733 ,\n",
       "        1.678   , -0.22731 , -0.19866 , -1.4406  , -0.92056 , -0.079727,\n",
       "       -0.11499 , -1.7283  , -0.34006 ,  0.055786,  0.075179,  0.27707 ,\n",
       "        0.52379 ,  1.3239  ,  0.79423 , -1.6663  , -0.048674,  0.55716 ,\n",
       "       -0.13412 ,  0.28476 ], dtype=float32)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(word2vec_transfer.key_to_index))\n",
    "print(len(word2vec_transfer['harassment']))\n",
    "word2vec_transfer['harassment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "7989d5b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T10:19:25.098861Z",
     "start_time": "2022-01-07T10:19:25.059070Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('harrasment', 0.7795867919921875),\n",
       " ('harassment', 0.7719964385032654),\n",
       " ('favoritism', 0.7004265189170837),\n",
       " ('gender-based', 0.697039008140564),\n",
       " ('intimidation', 0.6910016536712646),\n",
       " ('coercion', 0.6858652234077454),\n",
       " ('antigay', 0.6821078062057495),\n",
       " ('misbehavior', 0.6813644170761108),\n",
       " ('victimisation', 0.6743680834770203),\n",
       " ('mistreatment', 0.6710280776023865)]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_transfer.most_similar('harrassment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "46f03248",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T10:11:30.303121Z",
     "start_time": "2022-01-07T10:11:30.289584Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to convert a sentence (list of words) into a matrix representing the words in the embedding space\n",
    "def embed_sentence_with_TF(word2vec, sentence):\n",
    "    embedded_sentence = []\n",
    "    for word in sentence:\n",
    "        if word in word2vec:\n",
    "            embedded_sentence.append(word2vec[word])\n",
    "        \n",
    "    return np.array(embedded_sentence)\n",
    "\n",
    "# Function that converts a list of sentences into a list of matrices\n",
    "def embedding(word2vec, sentences):\n",
    "    embed = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        embedded_sentence = embed_sentence_with_TF(word2vec, sentence)\n",
    "        embed.append(embedded_sentence)\n",
    "        \n",
    "    return embed\n",
    "\n",
    "# Embed the training and test sentences\n",
    "X_train_embed_2 = embedding(word2vec_transfer, X_train)\n",
    "X_test_embed_2 = embedding(word2vec_transfer, X_test)\n",
    "\n",
    "# Pad the training and test embedded sentences\n",
    "X_train_pad_2 = pad_sequences(X_train_embed_2, dtype='float32', padding='post', maxlen=200)\n",
    "X_test_pad_2 = pad_sequences(X_test_embed_2, dtype='float32', padding='post', maxlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "73d95c52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T10:27:42.649056Z",
     "start_time": "2022-01-07T10:27:42.629874Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run new model\n",
    "\n",
    "es = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "model = init_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "f2f31a83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T10:12:56.673292Z",
     "start_time": "2022-01-07T10:12:43.571938Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 4s 922ms/step - loss: 0.6778 - accuracy: 0.6071 - val_loss: 0.6883 - val_accuracy: 0.5417\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.6577 - accuracy: 0.7143 - val_loss: 0.6863 - val_accuracy: 0.5417\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.6487 - accuracy: 0.6964 - val_loss: 0.6825 - val_accuracy: 0.5417\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.6346 - accuracy: 0.7500 - val_loss: 0.6835 - val_accuracy: 0.5417\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.6225 - accuracy: 0.7679 - val_loss: 0.6834 - val_accuracy: 0.5417\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.6121 - accuracy: 0.7500 - val_loss: 0.6807 - val_accuracy: 0.5417\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.6024 - accuracy: 0.7679 - val_loss: 0.6857 - val_accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.5889 - accuracy: 0.8214 - val_loss: 0.6825 - val_accuracy: 0.5417\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.5777 - accuracy: 0.8393 - val_loss: 0.6818 - val_accuracy: 0.5417\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.5663 - accuracy: 0.8214 - val_loss: 0.6794 - val_accuracy: 0.5417\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.5561 - accuracy: 0.8214 - val_loss: 0.6755 - val_accuracy: 0.5417\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.5510 - accuracy: 0.7857 - val_loss: 0.6710 - val_accuracy: 0.5417\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.5339 - accuracy: 0.8393 - val_loss: 0.6751 - val_accuracy: 0.5417\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.5227 - accuracy: 0.8393 - val_loss: 0.6769 - val_accuracy: 0.5833\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.5111 - accuracy: 0.8214 - val_loss: 0.6686 - val_accuracy: 0.5417\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 1s 346ms/step - loss: 0.4994 - accuracy: 0.8393 - val_loss: 0.6739 - val_accuracy: 0.5833\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 218ms/step - loss: 0.4847 - accuracy: 0.8393 - val_loss: 0.6672 - val_accuracy: 0.5833\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.4711 - accuracy: 0.8393 - val_loss: 0.6640 - val_accuracy: 0.5833\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 182ms/step - loss: 0.4628 - accuracy: 0.8571 - val_loss: 0.6454 - val_accuracy: 0.6250\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.4483 - accuracy: 0.8750 - val_loss: 0.6434 - val_accuracy: 0.6250\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.4346 - accuracy: 0.8750 - val_loss: 0.6641 - val_accuracy: 0.5833\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 1s 205ms/step - loss: 0.4167 - accuracy: 0.8929 - val_loss: 0.6490 - val_accuracy: 0.7083\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 358ms/step - loss: 0.4007 - accuracy: 0.9107 - val_loss: 0.6372 - val_accuracy: 0.7083\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.3873 - accuracy: 0.8750 - val_loss: 0.6507 - val_accuracy: 0.6667\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.3728 - accuracy: 0.9107 - val_loss: 0.6221 - val_accuracy: 0.7500\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 0.3581 - accuracy: 0.8929 - val_loss: 0.6423 - val_accuracy: 0.6667\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 263ms/step - loss: 0.3435 - accuracy: 0.9107 - val_loss: 0.6241 - val_accuracy: 0.7083\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.3426 - accuracy: 0.8929 - val_loss: 0.6056 - val_accuracy: 0.7500\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.3204 - accuracy: 0.9464 - val_loss: 0.6515 - val_accuracy: 0.6667\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.3078 - accuracy: 0.9286 - val_loss: 0.6546 - val_accuracy: 0.6667\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 0.2945 - accuracy: 0.9286 - val_loss: 0.6156 - val_accuracy: 0.7500\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.2834 - accuracy: 0.9464 - val_loss: 0.6516 - val_accuracy: 0.6667\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 376ms/step - loss: 0.2708 - accuracy: 0.9643 - val_loss: 0.6210 - val_accuracy: 0.7083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbcdc7ebe80>"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_pad_2, y_train, \n",
    "          batch_size = 32,\n",
    "          epochs=100,\n",
    "          validation_split=0.3,\n",
    "          callbacks=[es]\n",
    "         )\n",
    "## accuracy 0.7083"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94752d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "a491a3c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T10:15:04.349093Z",
     "start_time": "2022-01-07T10:15:04.247974Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy evaluated on the test set is of 70.000%\n"
     ]
    }
   ],
   "source": [
    "res = model.evaluate(X_test_pad_2, y_test, verbose=0)\n",
    "\n",
    "print(f'The accuracy evaluated on the test set is of {res[1]*100:.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0a1368",
   "metadata": {},
   "source": [
    "# Question to teachers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11859b09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T16:24:56.252728Z",
     "start_time": "2022-01-06T16:24:56.212677Z"
    }
   },
   "source": [
    "- Lementazing needed? yes--> reduce vocabulary_size in X_train\n",
    "- Removing stop_words ---> yes.\n",
    "- Why words in my X_train do not have embeddings with Word2Vec  --> depends on min_count\n",
    "- keep (top 20) emojis by replacing with some word  instead of removing in data prep? \n",
    "- should we remove numbers in words? ex. \"one\"\n",
    "\n",
    "- vector_size effect on embedding, not clear?---> seems like higher dimension better on most_similar words\n",
    "-! transfer embedding vs \"regular\" embedding? \n",
    "TE = use pre-trained model to represent my data in N-dim\n",
    "RE = use pre-defined NN to train on my data and represent in som N-dim ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c326be9",
   "metadata": {},
   "source": [
    "# Notes for myself"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d074aba0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T07:33:35.478757Z",
     "start_time": "2022-01-07T07:33:35.476368Z"
    }
   },
   "source": [
    "- !! some texts truncated example \"yeah....\" in sjekk\n",
    "- remove \"amp\"--> stands for &\n",
    "- Add confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "dbfc2d88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T10:25:44.556543Z",
     "start_time": "2022-01-07T10:25:44.551634Z"
    }
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(6,6))\n",
    "# cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "# sns.heatmap(cm, square=True, annot=True, cbar=False,\n",
    "#             xticklabels=['non-hate', 'hate'], yticklabels=['non-hate', 'hate'])\n",
    "# plt.xlabel('Predicted label')\n",
    "# plt.ylabel('True label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e0ce3e",
   "metadata": {},
   "source": [
    "## Transfer learning vs \"simple\" embedding\n",
    "\n",
    "- As mentionned ealier, Word2vec trains an internal Neural network whose goal is to predict a word in a corpus\n",
    "based on the words around it. This part of the sentence is called the window.\n",
    "Its size corresponds to the number of word around word W used to predict this word W\n",
    "\n",
    "- Instead of learning it on your training set (especially if it is very small), you can directly \n",
    "load a pretrained embedding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b118494",
   "metadata": {},
   "source": [
    "# Keras documentation\n",
    "\n",
    "- padding : https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences\n",
    "- embedding: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding#example_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5305e2c2",
   "metadata": {},
   "source": [
    "# Gensim word2vec documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befafaf9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T07:41:20.963944Z",
     "start_time": "2022-01-07T07:41:20.960192Z"
    }
   },
   "source": [
    "- https://radimrehurek.com/gensim/\n",
    "- https://radimrehurek.com/gensim/models/word2vec.html#usage-examples\n",
    "- https://radimrehurek.com/gensim/models/word2vec.html#usage-examples\n",
    "- hyperparameters: https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Text8Corpus\n",
    "- transfer learning : gensim-data repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8666cc",
   "metadata": {},
   "source": [
    "# To do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d53b07f",
   "metadata": {},
   "source": [
    "- twick Embedding hyperparameters to improve score\n",
    "- Understand the other layers and hyperparameters to tune\n",
    "- Improve data cleaning part (lemantizing?)\n",
    "- Run all on bigger datasett\n",
    "- ++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a151dbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "547.838px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
